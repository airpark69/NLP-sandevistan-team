{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skjaa0Gk6d_X"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dV3DzWTwjn0C"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqw5iRMA1XG",
        "outputId": "8d2abb3e-4e3b-4440-823f-6c21438557a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.3-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=3129533 sha256=b542345ee54c9ae778ad5492d53448b0aec224dd9fe90f427cf7997b1821523c\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151e99c4-ac0d-4445-b650-142a3eb2dfaf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자모 단위 FASTTEXT"
      ],
      "metadata": {
        "id": "f6F2ryDwmIcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hgtk"
      ],
      "metadata": {
        "id": "y3YLIC97EPvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eaadd7b-e876-4f1b-bab4-9ef81a97fa87"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hgtk\n",
            "  Downloading hgtk-0.1.3.tar.gz (6.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6688 sha256=73a7436b1968c6209b62e64cbb329d717e4f955428f1781b6de0b20739edf97b\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/33/b8/bc2256172a415340e34f3c11ef2b0f3f391769000bb74de988\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTHzbHFvGM-8",
        "outputId": "b6415e54-53c5-46ce-88c9-dc07298a1ecb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.6/465.6 KB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 29.57 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-14 23:42:22--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNPTOZRNWL&Signature=8OUQZarQj6ewou0HOZjyQxYZFa8%3D&x-amz-security-token=FwoGZXIvYXdzELH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDMshl0VaECH1CAN%2BRiK%2BAQMEErt0LpmfC6J9uSaJiy0DiM%2Fo8MEWlZcgmprA%2FCbMpJMvfWa8C689kerxVnJrwzO9HAj8zxzRsEe48avh0r8wl0YOb6i513wr6KUVfRJn%2BqRj9udmZfV8WFuSXgAyEoLc3VrD96UXSsHaEdQhLTP6A3rFu7IF811je3SElh%2Bw%2BivsTZWK78BKKmpfNp%2BKoI9kq1LGAH4Ly0C7Qbkcd9sMJm2NPWAglayed9rXzcLSBN09UkIxvs7BRweiTxoo3%2FuMngYyLYg%2B4SH2rEO%2F0xIx4A59gNOXYl0u2d4MY5oWKM3sQdbxVTy2BOSaNzPLzQxmaA%3D%3D&Expires=1673741543 [following]\n",
            "--2023-01-14 23:42:23--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNPTOZRNWL&Signature=8OUQZarQj6ewou0HOZjyQxYZFa8%3D&x-amz-security-token=FwoGZXIvYXdzELH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDMshl0VaECH1CAN%2BRiK%2BAQMEErt0LpmfC6J9uSaJiy0DiM%2Fo8MEWlZcgmprA%2FCbMpJMvfWa8C689kerxVnJrwzO9HAj8zxzRsEe48avh0r8wl0YOb6i513wr6KUVfRJn%2BqRj9udmZfV8WFuSXgAyEoLc3VrD96UXSsHaEdQhLTP6A3rFu7IF811je3SElh%2Bw%2BivsTZWK78BKKmpfNp%2BKoI9kq1LGAH4Ly0C7Qbkcd9sMJm2NPWAglayed9rXzcLSBN09UkIxvs7BRweiTxoo3%2FuMngYyLYg%2B4SH2rEO%2F0xIx4A59gNOXYl0u2d4MY5oWKM3sQdbxVTy2BOSaNzPLzQxmaA%3D%3D&Expires=1673741543\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.137.212, 52.217.86.60, 54.231.226.1, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.137.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.03MB/s    in 1.3s    \n",
            "\n",
            "2023-01-14 23:42:26 (1.03 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-14 23:43:45--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNPK5LEJNL&Signature=628Z7lBL%2B%2FZwXVbU6cSyFsland4%3D&x-amz-security-token=FwoGZXIvYXdzELH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDFtCx4dHMow6gB8SSyK%2BAShzgkOvlQLOFokgx88A9t53ayFIxsDUVlX8u8HVrnk0li6jX1e1c7MoqSYYDI1jE0ivrtQx%2Bj%2FoCcvEfb0%2By7pyPct2QQV%2F0ySQ8nsbht4RSwTeWojxQOUOrFvmCCVN7OEn3QZorSy0BAf2ysI25zIDgyfkSQhXzumCh49dHT5vdf7cPPcY6tTet3x%2FH5bvke6jj7rrgTTh0ltQFCT4GQK8%2BSFaubPIJWavGePvpkG9OJ66ZIDrM%2FBUFeSDdVUosvyMngYyLfPi3ic7cxR3TQz%2BgjygYp00vNvwF9ugMAyqE61mffofbZ5UmnnYSWNN6fUvEA%3D%3D&Expires=1673741626 [following]\n",
            "--2023-01-14 23:43:46--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNPK5LEJNL&Signature=628Z7lBL%2B%2FZwXVbU6cSyFsland4%3D&x-amz-security-token=FwoGZXIvYXdzELH%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDFtCx4dHMow6gB8SSyK%2BAShzgkOvlQLOFokgx88A9t53ayFIxsDUVlX8u8HVrnk0li6jX1e1c7MoqSYYDI1jE0ivrtQx%2Bj%2FoCcvEfb0%2By7pyPct2QQV%2F0ySQ8nsbht4RSwTeWojxQOUOrFvmCCVN7OEn3QZorSy0BAf2ysI25zIDgyfkSQhXzumCh49dHT5vdf7cPPcY6tTet3x%2FH5bvke6jj7rrgTTh0ltQFCT4GQK8%2BSFaubPIJWavGePvpkG9OJ66ZIDrM%2FBUFeSDdVUosvyMngYyLfPi3ic7cxR3TQz%2BgjygYp00vNvwF9ugMAyqE61mffofbZ5UmnnYSWNN6fUvEA%3D%3D&Expires=1673741626\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.217.137, 52.217.98.140, 52.216.221.217, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.217.137|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  10.8MB/s    in 5.0s    \n",
            "\n",
            "2023-01-14 23:43:52 (9.45 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hgtk\n",
        "from tqdm import tqdm\n",
        "from konlpy.tag import Mecab, Okt\n",
        "\n",
        "def word_to_jamo(token):\n",
        "    def to_special_token(jamo):\n",
        "      if not jamo:\n",
        "        return '-'\n",
        "      else:\n",
        "        return jamo\n",
        "    decomposed_token = ''\n",
        "\n",
        "    for char in token:\n",
        "        try:\n",
        "        # char( 음 절 ) 을 초 성 , 중 성 , 종 성 으 로 분 리\n",
        "            cho, jung, jong = hgtk.letter.decompose(char)\n",
        "\n",
        "            # 자 모 가 빈 문 자 일 경 우 특 수 문 자 - 로 대 체\n",
        "            cho = to_special_token(cho)\n",
        "            jung = to_special_token(jung)\n",
        "            jong = to_special_token(jong)\n",
        "            #decomposed_token = decomposed_token + cho + jung + jong\n",
        "            decomposed_token = decomposed_token + cho ## 초성만 넣을 경우의 테스트\n",
        "\n",
        "        # 만 약 char( 음 절 ) 이 한 글 이 아 닐 경 우 자 모 를 나 누 지 않 고 추 가\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                decomposed_token += char\n",
        "\n",
        "    # 단 어 토 큰 의 자 모 단 위 분 리 결 과 를 추 가\n",
        "    return decomposed_token\n",
        "\n",
        "\n",
        "#mecab = Okt()\n",
        "mecab = Mecab()\n",
        "\n",
        "def tokenize_by_jamo(s):\n",
        "    return [word_to_jamo(token) for token in mecab.morphs(s)]\n"
      ],
      "metadata": {
        "id": "iTDOSr3bDjjv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_by_jamo(\"간장 치킨\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dKvEZDMkAex",
        "outputId": "f9f09604-6821-475e-ab3c-f532fbbc37e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ㄱㅏㄴㅈㅏㅇ', 'ㅊㅣ-ㅋㅣㄴ']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/real_finish.csv\")"
      ],
      "metadata": {
        "id": "ypE5qU_PH43Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "AafhYBUTrT7p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/Kor_standard_menu.csv\", encoding='cp949')"
      ],
      "metadata": {
        "id": "vsjUSFaLxWYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['식품대분류명'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj_tfbUNyhHp",
        "outputId": "564c6f3e-ef4d-4350-e809-83c203422a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "빵 및 과자류         4012\n",
              "음료 및 차류         2262\n",
              "유제품류 및 빙과류       363\n",
              "볶음류              204\n",
              "국 및 탕류           182\n",
              "밥류               179\n",
              "생채·무침류           173\n",
              "면 및 만두류          166\n",
              "찌개 및 전골류         152\n",
              "구이류              120\n",
              "찜류                94\n",
              "전·적 및 부침류         77\n",
              "조림류               75\n",
              "나물·숙채류            73\n",
              "튀김류               50\n",
              "죽 및 스프류           46\n",
              "김치류               30\n",
              "장아찌·절임류           18\n",
              "젓갈류                9\n",
              "수·조·어·육류           7\n",
              "장류, 양념류            5\n",
              "곡류, 서류 제품          3\n",
              "두류, 견과 및 종실류       2\n",
              "과일류                1\n",
              "Name: 식품대분류명, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['업체명'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0exf-MH4y1D1",
        "outputId": "83b33c6c-a3a5-4343-94e2-4608038f45de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "해당없음         1639\n",
              "지정환피자         432\n",
              "투썸 플레이스       301\n",
              "스타벅스          256\n",
              "요거프레소         248\n",
              "             ... \n",
              "프랭크버거           9\n",
              "망원동티라미수         8\n",
              "신세계푸드 피코크       6\n",
              "CJ 쿡킷           6\n",
              "코코호도            1\n",
              "Name: 업체명, Length: 91, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['식품명', '식품대분류명', '대표식품명']]"
      ],
      "metadata": {
        "id": "icDV4ylrzC3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "wHMkG_QWydnb",
        "outputId": "6017cbee-031e-4a21-fb2d-8fe16828e8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-a74c58233b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'info'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['title', 'large_category', 'category']"
      ],
      "metadata": {
        "id": "nqYtPxV7xfY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'] = df['title'].replace('_', ' ', regex=True)"
      ],
      "metadata": {
        "id": "eztDi3vlHxAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"Kor_standard_menu_clean.csv\")"
      ],
      "metadata": {
        "id": "JH0V66yj126g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "hanspell 사용을 위해서 500자까지 채워넣는 방식 검토중\n",
        "\n",
        "\n",
        "-> hanspell 자체를 사용하지 않는 방향으로 생각"
      ],
      "metadata": {
        "id": "Nd3STvMSb6t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_str = ''\n",
        "tmp_max = 500\n",
        "\n",
        "i = 0\n",
        "while len(tmp_str) < tmp_max:\n",
        "  if len(tmp_str) >= tmp_max:\n",
        "    break\n",
        "  tmp_str += df['title'][i]\n",
        "  i += 1\n",
        "\n",
        "tmp_str"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "ZFkiyePCXBX2",
        "outputId": "5e3b72dd-b920-4a88-d8d0-fda3dad24e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 배추 김치 포기 김장김치 주문피코크 조선호텔 포기김치대상 종가집 행복이온 포기김치대상 종가집 전라도 행복이온 포기김치선화동매운실비김치 맛있게 매운 선화동 실비 김치엄마손맛 포기김치대상 종가집 우리땅배추김치 태백옥과맛있는김치 김권태김치 포기 배추 김치홍진경더김치 포기김치대상 종가집 포기김치팔공 명품 배추김치안동학가산김치 안동학가산 배추김치풀무원 사계절 아삭 포기김치대상 종가집 전라도 포기김치전라도 해남 김장 포기 김치빅마마 이혜정의 맛있는 포기김치팔공산김치 팔공산 명품포기김치바로푸드 친정김치 배추김치착한김치 맛없다면 무료반품나홀로족세트상품 대전 선화동실비김치국내산 고랭지 포기김치 대상수상 김치김춘자명인 포기 배추 김치 김장김치 주문안동학가산김치 국내산 배추 포기김치 산지직송노브랜드 별미 포기김치안동학가산 고랭지 포기김치총각김치 깍두기 외대복식품 한복선 대복 포기김치종가집 국산 포기김치 태백 남도 종갓집 배추김치 갓담은 김장종가집 김장김치 증정 총각김치제일제당 비비고 포기배추김치'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_str_blank_del = tmp_str.replace(\" \", '')"
      ],
      "metadata": {
        "id": "5PFKzGJ_ZMkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_str_blank_del"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "1_0Pa73EZQhh",
        "outputId": "70520fa9-d9e7-4586-fb74-dd2ebf572c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산배추김치포기김장김치주문피코크조선호텔포기김치대상종가집행복이온포기김치대상종가집전라도행복이온포기김치선화동매운실비김치맛있게매운선화동실비김치엄마손맛포기김치대상종가집우리땅배추김치태백옥과맛있는김치김권태김치포기배추김치홍진경더김치포기김치대상종가집포기김치팔공명품배추김치안동학가산김치안동학가산배추김치풀무원사계절아삭포기김치대상종가집전라도포기김치전라도해남김장포기김치빅마마이혜정의맛있는포기김치팔공산김치팔공산명품포기김치바로푸드친정김치배추김치착한김치맛없다면무료반품나홀로족세트상품대전선화동실비김치국내산고랭지포기김치대상수상김치김춘자명인포기배추김치김장김치주문안동학가산김치국내산배추포기김치산지직송노브랜드별미포기김치안동학가산고랭지포기김치총각김치깍두기외대복식품한복선대복포기김치종가집국산포기김치태백남도종갓집배추김치갓담은김장종가집김장김치증정총각김치제일제당비비고포기배추김치'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell_check(tmp_str_blank_del)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "8JF9GEUMZYvB",
        "outputId": "213db79b-7e79-4db0-cdec-78d32be0163e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산배추김치포기김장김치주문피코크조선호텔포기김치대상종가집행복이온포기김치대상종가집전라도행복이온포기김치선화동매운실비김치맛있게매운선화동실비김치엄마손맛포기김치대상종가집우리땅배추김치태백옥과맛있는김치김권태김치포기배추김치홍진경더김치포기김치대상종가집포기김치팔공명품배추김치안동학가산김치안동학가산배추김치풀무원사계절아삭포기김치대상종가집전라도포기김치전라도해남김장포기김치빅마마이혜정의맛있는포기김치팔공산김치팔공산명품포기김치바로푸드친정김치배추김치착한김치맛없다면무료반품나홀로족세트상품대전선화동실비김치국내산고랭지포기김치대상수상김치김춘자명인포기배추김치김장김치주문안동학가산김치국내산배추포기김치산지직송노브랜드별미포기김치안동학가산고랭지포기김치총각김치깍두기외대복식품한복선대복포기김치종가집국산포기김치태백남도종갓집배추김치갓담은김장종가집김장김치증정총각김치제일제당비비고포기배추김치'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_str = \"국내산국시\"\n",
        "test_str2 = \"국래산국시\""
      ],
      "metadata": {
        "id": "YESBIdnmbjc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spell_check(test_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "utoZskJEbrRH",
        "outputId": "112cf963-05c3-4b0b-8267-ac0bbc909fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 국시'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell_check(test_str2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jwEr-g6abu0z",
        "outputId": "73e3a04b-b106-4480-e0a0-8e448ed975bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 국시'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "국시 -> 국수 로 바꿔줘야 하는데 hanspell은 이런 도메인 특화의 표준화는 하지 못함"
      ],
      "metadata": {
        "id": "5lzuIkd6cCmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['title'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhA_td4iWVv6",
        "outputId": "e9a6c7a3-3875-46d0-8395-267ea39612ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XJ7mNXlAWb_B",
        "outputId": "e5c7f0c6-0dce-416b-fb87-4541f86af729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 배추 김치 포기 김장김치 주문'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.10, random_state=2)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=2)"
      ],
      "metadata": {
        "id": "pDhS9DVRpLW2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['sub_category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQun6IxkCb9S",
        "outputId": "8393a589-2afc-4ad5-e9f1-4ffc4b8d3972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "차류            15382\n",
              "커피             8921\n",
              "가루/분말류         5203\n",
              "도시락/밥류         3913\n",
              "해산물/어패류        3571\n",
              "              ...  \n",
              "피자/핫도그/햄버거        3\n",
              "세트                3\n",
              "겉절이               2\n",
              "절임배추              1\n",
              "오이소박이             1\n",
              "Name: sub_category, Length: 195, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 데이터 불균형이 심해서 가중치가 제대로 반영이 안되는 현상이 있음"
      ],
      "metadata": {
        "id": "JRFvZtnMPwf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4JF4av9mFXLB",
        "outputId": "1929d213-fd3c-4290-ab8f-2bd9c37ce5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 배추 김치 포기 김장김치 주문'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_jamo(\"바나나우유\")"
      ],
      "metadata": {
        "id": "CYuu2vG3P5EC",
        "outputId": "a4f3c837-6ea2-462e-b1dd-5e6a28a098b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ㅂㅏ-ㄴㅏ-ㄴㅏ-ㅇㅜ-ㅇㅠ-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_jamo(\"바나나 우유\")"
      ],
      "metadata": {
        "id": "u8Todzy5P8M3",
        "outputId": "38db4333-1174-44f3-e7e1-42a2a0d73775",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ㅂㅏ-ㄴㅏ-ㄴㅏ- ㅇㅜ-ㅇㅠ-'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_jamo(df['title'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Iu9VXN2MFLGu",
        "outputId": "80f5b921-5cea-424f-ad76-8f322ccaa3d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ㄱㅜㄱㄴㅐ-ㅅㅏㄴ ㅂㅐ-ㅊㅜ- ㄱㅣㅁㅊㅣ- ㅍㅗ-ㄱㅣ- ㄱㅣㅁㅈㅏㅇㄱㅣㅁㅊㅣ- ㅈㅜ-ㅁㅜㄴ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize_by_jamo(df['title'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0anP89z1I3JJ",
        "outputId": "145dba1f-4571-488f-e644-0a079255ca42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㄱㅜㄱㄴㅐ-ㅅㅏㄴ', '100', '%', 'ㅈㅓㄴㄹㅏ-ㄷㅗ-', 'ㅂㅐ-ㅊㅜ-', 'ㄱㅣㅁㅊㅣ-', 'ㅍㅗ-ㄱㅣ-', 'ㄱㅣㅁㅈㅏㅇ', 'ㄱㅣㅁㅊㅣ-', 'ㅈㅜ-ㅁㅜㄴ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data['title'].to_list()):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "boO9ZhMQF-3u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jamo_to_word(jamo_sequence):\n",
        "    tokenized_jamo = []\n",
        "    index = 0\n",
        "\n",
        "# 1. 초 기 입 력\n",
        "# jamo_sequence = ' ﾤ ￂ ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "\n",
        "    while index < len(jamo_sequence):\n",
        "    # 문 자 가 한 글 ( 정 상 적 인 자 모 ) 이 아 닐 경 우\n",
        "        if not hgtk.checker.is_hangul(jamo_sequence[index]):\n",
        "            tokenized_jamo.append(jamo_sequence[index])\n",
        "            index = index + 1\n",
        "\n",
        "    # 문 자 가 정 상 적 인 자 모 라 면 초 성 , 중 성 , 종 성 을 하 나 의 토 큰 으 로 간 주 .\n",
        "        else:\n",
        "            tokenized_jamo.append(jamo_sequence[index:index + 3])\n",
        "            index = index + 3\n",
        "\n",
        "# 2. 자 모 단 위 토 큰 화 완 료\n",
        "# tokenized_jamo : [' ﾤ ￂ ﾱ ', ' ﾧ ￌ ﾷ ', ' ﾵ ￃ ﾷ ']\n",
        "\n",
        "        word = ''\n",
        "        try:\n",
        "            for jamo in tokenized_jamo:\n",
        "            # 초 성 , 중 성 , 종 성 의 묶 음 으 로 추 정 되 는 경 우\n",
        "                if len(jamo) == 3:\n",
        "                    if jamo[2] == \"-\":\n",
        "                    # 종 성 이 존 재 하 지 않 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1])\n",
        "                    else:\n",
        "                # 종 성 이 존 재 하 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1], jamo[2])\n",
        "                # 한 글 이 아 닌 경 우\n",
        "                else:\n",
        "                    word = word + jamo\n",
        "\n",
        "            # 복 원 중 (hgtk.letter.compose) 에 러 발 생 시 초 기 입 력 리 턴 .\n",
        "            # 복 원 이 불 가 능 한 경 우 예 시 ) ' ﾤ ! ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                return jamo_sequence\n",
        "\n",
        "        # 3. 단 어 로 복 원 완 료\n",
        "        # word : ' 남 동 생 '\n",
        "\n",
        "    return word"
      ],
      "metadata": {
        "id": "Y2lnPxhNJY4Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.reset_index(inplace=True)\n",
        "val_data.reset_index(inplace=True)\n",
        "test_data.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "8pzgFzNZrc0D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "맞춤법 검사 hanspell 은 2000개에 1시간이 걸린다. 활용할 방법을 찾아야 할듯"
      ],
      "metadata": {
        "id": "-xYGQ0I6Vkr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = tokenized(train_data)\n",
        "val_token = tokenized(val_data)\n",
        "test_token = tokenized(test_data)\n",
        "df_token = tokenized(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkQfXjWJp29y",
        "outputId": "d7e7cd71-2cab-4ebb-83de-6e0bb5ba8392"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157114/157114 [00:18<00:00, 8492.86it/s]\n",
            "100%|██████████| 27727/27727 [00:03<00:00, 7231.50it/s]\n",
            "100%|██████████| 20538/20538 [00:02<00:00, 9012.92it/s]\n",
            "100%|██████████| 205379/205379 [00:21<00:00, 9689.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(train_token)), unit=' line'):\n",
        "          out.write(\"__label__\" + train_data['category'][i] + \"\\t\" + ' '.join(train_token[i]) + '\\n')\n",
        "\n",
        "with open('val_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(val_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + val_data['category'][i] + \"\\t\" + ' '.join(val_token[i]) + '\\n')\n",
        "\n",
        "with open('test_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(test_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + test_data['category'][i] + \"\\t\" + ' '.join(test_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyFcLFfbLeFq",
        "outputId": "9672f447-e433-4558-bff8-9d5bba27d40a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157114/157114 [00:01<00:00, 155698.93 line/s]\n",
            "100%|██████████| 27727/27727 [00:00<00:00, 159892.58 line/s]\n",
            "100%|██████████| 20538/20538 [00:00<00:00, 156239.16 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('df_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(df_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + df['category'][i] + \"\\t\" + ' '.join(df_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMQvm-2RVjBA",
        "outputId": "cdcdd970-571a-48e5-a9b0-6cd90662ad95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8303/8303 [00:00<00:00, 114051.57 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gensim을 통한 학습"
      ],
      "metadata": {
        "id": "v58EQIwhKa8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "0FGsnERINFyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --upgrade"
      ],
      "metadata": {
        "id": "wh95tWgWNmPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "tevwnl1qej2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.utils import tokenize\n",
        "from gensim import utils\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "class MyIter:\n",
        "    def __iter__(self):\n",
        "        path = datapath('/content/test_data.txt')\n",
        "        with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "            for line in fin:\n",
        "                yield list(tokenize(line))\n",
        "\n",
        "model3 = FastText(vector_size=4, window=3, min_count=1)\n",
        "model3.build_vocab(corpus_iterable=MyIter())\n",
        "total_examples = model3.corpus_count\n",
        "model3.train(corpus_iterable=MyIter(), total_examples=total_examples, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uim-4v9KsfE",
        "outputId": "ee8dbd8f-5c01-4279-99e6-902e3b02e70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3276530, 4152075)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 저장"
      ],
      "metadata": {
        "id": "jf11-LHlOB57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname = 'fasttext'"
      ],
      "metadata": {
        "id": "M8O1dPKhPXgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "model3.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "LvvSg8yvOBZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = FastText.load(model_fname)"
      ],
      "metadata": {
        "id": "ssaAMu6KOKiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_gensim(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (word, similarity) in word_sequence]"
      ],
      "metadata": {
        "id": "iQvu47RyWlq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"찜닭\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nDbdO1oP1u7",
        "outputId": "c7015546-6d52-428e-9cd8-d1d2ba22a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('맛있', 0.9995765686035156),\n",
              " ('냉동', 0.9995282292366028),\n",
              " ('냉장육', 0.9994854927062988),\n",
              " ('목살', 0.9984344840049744),\n",
              " ('통살', 0.9979778528213501)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"볶음밥\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmckWbVCQXh2",
        "outputId": "57fb23da-e4e3-4cca-ce03-beeb6b59345c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('덮밥', 0.9965663552284241),\n",
              " ('즉', 0.996501088142395),\n",
              " ('닭볶음밥', 0.996482253074646),\n",
              " ('쌈밥', 0.9961134791374207),\n",
              " ('맙', 0.9931130409240723)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "업데이트"
      ],
      "metadata": {
        "id": "2E4-py6wRjLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/train_data.txt')\n",
        "old_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      old_vector.append(line)"
      ],
      "metadata": {
        "id": "_yS6qanXVGAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/val_data.txt')\n",
        "new_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      new_vector.append(line)"
      ],
      "metadata": {
        "id": "40_TR9jkSu5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.allclose(old_vector, new_vector, atol=1e-4)"
      ],
      "metadata": {
        "id": "9kvVIoqURWg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.build_vocab(new_vector, update=True)\n",
        "model3.train(new_vector, total_examples=len(new_vector), epochs=model3.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KupFKwWRkQc",
        "outputId": "273949d3-c9a7-4733-a1a6-fb2597ed5cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6759131, 21611110)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.train_supervised(input='train_data.txt', autotuneValidationFile='val_data.txt')"
      ],
      "metadata": {
        "id": "W7E-dIoPM2C2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(word_to_jamo(\"삼계죽\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k54Mp1ZINtE3",
        "outputId": "e93ff020-f931-44d6-c0d9-a77cc6132f87"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__전통주',), array([0.99090558]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\"ㅊㅋ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhnH5TwquGdS",
        "outputId": "835ee6cc-6db3-4833-ca5c-a1d91d14c340"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__냉동/간편조리식품',), array([0.9279654]))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\"ㅋㅍ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUNSwH32vIXi",
        "outputId": "2028f6a3-5a11-4fb9-c44f-cafb6e4bbab1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__커피/차류',), array([0.99869269]))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\"ㄱㅊ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij12dVzWvKPH",
        "outputId": "908e9653-c4c8-4c07-f76d-126da5c00ee4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__김치',), array([1.00001001]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(\"ㅅㄱㅅ\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNyJ6iFrvSmY",
        "outputId": "e3558ac6-de2d-407d-8697-0d252cc00dce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__축산물',), array([1.00000036]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트\n",
        "결과는 (샘플, 정확도, 재현율)"
      ],
      "metadata": {
        "id": "HjRzmMlgrSwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.test(\"test_data.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zmCeRBugwk",
        "outputId": "46a17329-19a3-4261-e7b0-b4d380652831"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20538, 0.8758399065147532, 0.8758399065147532)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NAVER 데이터셋\n",
        "- 초성만을 넣은 상태에서도 특정 키워드의 예측은 잘되었다.\n",
        "\n",
        "\n",
        "- 테스트 정확도가 0.8758 정도로 초성만을 사용하면 정확도가 약간은 내려가지만 분명히 초성이 중요한 특성임을 알려주고 있다."
      ],
      "metadata": {
        "id": "IzbhW-VLrbRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"fasttext_supervised_basemodel.bin\") # 모 델 저 장"
      ],
      "metadata": {
        "id": "cypb4feXHBZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model2 = fasttext.train_unsupervised('df_data.txt', model='skipgram')"
      ],
      "metadata": {
        "id": "KehDpoTGH7OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.get_nearest_neighbors(word_to_jamo(\"찜닭\"), k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1R4dz_K1Wo",
        "outputId": "1250ef0a-9dc7-44bf-f3f6-b6ca213395da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.9999814629554749, 'ㄷㅏㄺㅉㅣㅁ'),\n",
              " (0.9999790787696838, 'ㅉㅣㅁ'),\n",
              " (0.9999781847000122, 'ㄱㅏㄹㅂㅣ-ㅉㅣㅁ'),\n",
              " (0.9999775290489197, 'ㅇㅑㅇㄴㅕㅁ'),\n",
              " (0.9999749064445496, 'ㄱㅗ-ㅊㅜ-ㅈㅏㅇ'),\n",
              " (0.9999746084213257, 'ㅁㅐ-ㅇㅜㄴ'),\n",
              " (0.9999740719795227, 'ㅁㅐ-ㅇㅜㄴㅌㅏㅇ'),\n",
              " (0.999971866607666, 'ㅂㅣ-ㅂㅣㅁㅂㅏㅂ'),\n",
              " (0.9999716877937317, 'ㄷㅏㄺㅌㅟ-ㄱㅣㅁ'),\n",
              " (0.9999716877937317, 'ㄱㅗ-ㅊㅜ-')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (similarity, word) in word_sequence]"
      ],
      "metadata": {
        "id": "XvaOGu6_LH-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 가까운 단어(유사도 기준)"
      ],
      "metadata": {
        "id": "LqwRaWuPM0QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform(model2.get_nearest_neighbors(word_to_jamo(\"치킨\"), k=10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7wCdsuqLO1W",
        "outputId": "4d9ccd51-e62f-4c01-cf70-9e293bcba736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('흑미', 0.9999756217002869), ('백미', 0.9999728202819824), ('스위티', 0.9999725222587585), ('도이치', 0.9999719262123108), ('가자미', 0.9999687075614929), ('리코타', 0.9999684691429138), ('이탈리안', 0.9999672770500183), ('통밀', 0.999966561794281), ('자바', 0.9999661445617676), ('생강차', 0.9999660849571228)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유추(의미 기준)"
      ],
      "metadata": {
        "id": "a7ZJ4YpeMzJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform(model2.get_analogies(word_to_jamo(\"치킨\"), word_to_jamo(\"양념\"), word_to_jamo(\"마늘\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBF5jhRgL7Kw",
        "outputId": "6b836f01-24ec-46b9-ed06-afd6e3e69a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('치아', 0.999954104423523),\n",
              " ('코코아', 0.999951958656311),\n",
              " ('바닐라', 0.9999518990516663),\n",
              " ('디아', 0.9999489188194275),\n",
              " ('슈페너', 0.9999486804008484),\n",
              " ('페페', 0.9999475479125977),\n",
              " ('페퍼민트', 0.9999456405639648),\n",
              " ('스퀘어', 0.9999456405639648),\n",
              " ('페퍼로니', 0.9999446868896484),\n",
              " ('루미', 0.9999446272850037)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 저장된 모델 DB에 삽입 과정 "
      ],
      "metadata": {
        "id": "jOL2AKFjVvz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOB 방식은 안된다. bin을 BLOB로 파싱하는데 무리가 있다"
      ],
      "metadata": {
        "id": "lNAZ3GBrZ5c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNOxkX_sV17c",
        "outputId": "161715f4-f563-463f-958a-049eff2a38dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting config\n",
            "  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import numpy\n",
        "from psycopg2.extensions import register_adapter, AsIs\n",
        "  \n",
        "def addapt_numpy_float64(numpy_float64):\n",
        "    return AsIs(numpy_float64)\n",
        "def addapt_numpy_int64(numpy_int64):\n",
        "    return AsIs(numpy_int64)\n",
        "register_adapter(numpy.float64, addapt_numpy_float64)\n",
        "register_adapter(numpy.int64, addapt_numpy_int64)\n",
        "\n",
        "conn = None\n",
        "try:\n",
        "    # connect to the PostgreSQL server\n",
        "    host = 'arjuna.db.elephantsql.com'\n",
        "    user = 'kwcuclpe'\n",
        "    password = ''\n",
        "    database = 'kwcuclpe'\n",
        "\n",
        "    conn = psycopg2.connect(\n",
        "        host=host,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "  \n",
        "    # Creating a cursor with name cur.\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"CREATE TABLE blob_datastore (s_no serial, file_name VARCHAR ( 50 ), blob_data bytea)\")\n",
        "    # SQL query to insert data into the database.\n",
        "    insert_script = '''\n",
        "        INSERT INTO blob_datastore(s_no,file_name,blob_data) VALUES (%s,%s,%s);\n",
        "    '''\n",
        "  \n",
        "    # open('File,'rb').read() is used to read the file.\n",
        "    # where open(File,'rb').read() will return the binary data of the file.\n",
        "    # psycopg2.Binary(File_in_Bytes) is used to convert the binary data to a BLOB data type.\n",
        "    BLOB_1 = psycopg2.Binary(\n",
        "        open('/content/fasttext_supervised_basemodel.bin', 'rb').read())       # Video\n",
        "    # BLOB_2 = psycopg2.Binary(\n",
        "    #     open('files\\Octa.jpg', 'rb').read())        # Image\n",
        "    # BLOB_3 = psycopg2.Binary(open('files\\Type.gif', 'rb').read())        # GIF\n",
        "    # BLOB_4 = psycopg2.Binary(open('files\\BlobNotes.pdf', 'rb').read())   # PDF\n",
        "  \n",
        "    # And Finally we pass the above mentioned values to the insert_script variable.\n",
        "    insert_values = [(1, 'fasttext_basemodel', BLOB_1)]\n",
        "  \n",
        "    # The execute() method with the insert_script & insert_value as argument.\n",
        "    for insert_value in insert_values:\n",
        "        cur.execute(insert_script, insert_value)\n",
        "        print(insert_value[0], insert_value[1],\n",
        "              \"[Binary Data]\", \"row Inserted Successfully\")\n",
        "  \n",
        "    # SQL query to fetch data from the database.\n",
        "    cur.execute('SELECT * FROM BLOB_DataStore')\n",
        "  \n",
        "    # open(file,'wb').write() is used to write the binary data to the file.\n",
        "    for row in cur.fetchall():\n",
        "        BLOB = row[2]\n",
        "        open(\"new\"+row[1], 'wb').write(BLOB)\n",
        "        print(row[0], row[1], \"BLOB Data is saved in Current Directory\")\n",
        "  \n",
        "    # Close the connection\n",
        "    cur.close()\n",
        "  \n",
        "except(Exception, psycopg2.DatabaseError) as error:\n",
        "    print(error)\n",
        "finally:\n",
        "    if conn is not None:\n",
        "        \n",
        "        # Commit the changes to the database\n",
        "        conn.commit()"
      ],
      "metadata": {
        "id": "M_ylq5qNV0HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이에 따라 워드임베딩만 fastText로 진행하고, 모델은 SVM을 사용하여 피클링을 시도해본다."
      ],
      "metadata": {
        "id": "excSxmr4d7hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "8hTZcNw6EaYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "## 환경설정\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import nltk"
      ],
      "metadata": {
        "id": "6ewbIutpebUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/final_clean.csv\")"
      ],
      "metadata": {
        "id": "cBi0btIpedX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\"/content/Kor_standard_menu_clean.csv\")"
      ],
      "metadata": {
        "id": "6GFbhIiBFp6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['sub_category'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu8sxXcBetun",
        "outputId": "d1b50a0b-b15a-4b7d-c0b4-389e5260bc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "차류          20143\n",
              "커피          11648\n",
              "가루분말류        7384\n",
              "도시락밥류        6485\n",
              "해산물어패류       4448\n",
              "            ...  \n",
              "옥수수콩            3\n",
              "피자핫도그햄버거        3\n",
              "세트              3\n",
              "절임배추            1\n",
              "오이소박이           1\n",
              "Name: sub_category, Length: 195, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_corpus, test_corpus, train_label_names, test_label_names =\\\n",
        "#                                  train_test_split(np.array(data_df['title']), np.array(data_df['sub_category']),\n",
        "#                                                        test_size=0.33, random_state=42)\n",
        "train_corpus, test_corpus = train_test_split(data_df, test_size=0.2, random_state=42)\n",
        "#train_corpus, val_corpus = train_test_split(data_df, test_size=0.15, random_state=42)\n",
        "\n",
        "feature = 'title'\n",
        "target = 'category'\n",
        "\n",
        "train_label_names = train_corpus[target]\n",
        "#val_label_names = val_corpus[target]\n",
        "test_label_names = test_corpus[target]\n",
        "\n",
        "train_corpus = train_corpus['title']\n",
        "#val_corpus = val_corpus['title']\n",
        "test_corpus = test_corpus['title']\n",
        "\n",
        "train_corpus.shape, test_corpus.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onZhWYOBesEC",
        "outputId": "b17b1c1e-196a-4ece-8f14-dfe97e51a7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6642,), (1661,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "JEhrWhWUgzXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = tokenized(train_corpus)\n",
        "#tokenized_val = tokenized(val_corpus)\n",
        "tokenized_test = tokenized(test_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRVe65age_94",
        "outputId": "c87d0a73-c1e3-48fe-b06b-bd51b2c19307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6642/6642 [00:00<00:00, 12296.02it/s]\n",
            "100%|██████████| 1661/1661 [00:00<00:00, 12804.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 준비 및 실행"
      ],
      "metadata": {
        "id": "a4MXjkxqEc0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gensim 4.3.0 기준 , 코랩은 업그레이드 해야함"
      ],
      "metadata": {
        "id": "GQtE55LgiVvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "RdtA9VM3GFZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-Xj5W6YGcVv",
        "outputId": "2429c65d-6113-4724-c50e-a88f8594f3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.24.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.7.3 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "ft_num_features = 400 # 4의 배수에서 좋은 성능이 나온다고 함"
      ],
      "metadata": {
        "id": "nC91wbEsEVWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6933c5-1cb1-456d-f92e-529cb2a88e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
        "ft_model = FastText(tokenized_train, vector_size=ft_num_features, window=50, \n",
        "                    min_count=1, sample=1e-3, sg=1, workers=10)"
      ],
      "metadata": {
        "id": "sVio9k_QeDuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname=f\"/gdrive/MyDrive/2023beaver/fastText_{ft_num_features}\""
      ],
      "metadata": {
        "id": "rKFmjHZkDp8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "ft_model.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "FP1OqH4tm_TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미 저장된 모델 로드"
      ],
      "metadata": {
        "id": "CK-4YhbMEjL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "ft_model = FastText.load(model_fname)"
      ],
      "metadata": {
        "id": "awcnpWd3DdzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastText 워드임베딩 pickle화 시도\n",
        "\n",
        "-> 가능은 한데, 용량이 1.3G로 상당히 크다. 문제 해결 X"
      ],
      "metadata": {
        "id": "XFW5nl54OkBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = model_fname + \".pickle\"\n",
        "pickle.dump(ft_model, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "aYKhna72OYe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "joblib을 통한 압축 시도\n",
        "\n",
        "compress 파라미터가 압축을 의미하며, 높을수록 오래걸리지만 용량이 적어진다.(0 ~ 9까지)\n",
        "\n",
        "https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html\n",
        "\n",
        "compress 9 (최대)에서 710M까지 줄여졌다.\n",
        "\n",
        "-> 여전히 문제 해결X"
      ],
      "metadata": {
        "id": "JbAz-fztQsYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "filename = model_fname + \".joblib\"\n",
        "\n",
        "# save model\n",
        "joblib.dump(ft_model, filename, compress=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skM7lumwQwAa",
        "outputId": "acdc268f-c2ba-4171-9a0f-387dede2cda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/2023beaver/fastText_40.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def document_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index_to_key)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in tqdm(corpus)]\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "BgnbXWVAfyPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_ft_train_features = document_vectorizer(corpus=tokenized_train, model=ft_model,\n",
        "                                                     num_features=ft_num_features)\n",
        "# avg_ft_val_features = document_vectorizer(corpus=tokenized_val, model=ft_model,\n",
        "#                                                      num_features=ft_num_features)\n",
        "avg_ft_test_features = document_vectorizer(corpus=tokenized_test, model=ft_model,\n",
        "                                                    num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "uP9ueVfxfo_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409221af-7f0e-4123-84ba-0a76fc04f56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6642/6642 [00:00<00:00, 39262.80it/s]\n",
            "100%|██████████| 1661/1661 [00:00<00:00, 41430.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('FastText model:> Train features shape:', avg_ft_train_features.shape)\n",
        "#print(' Val features shape:', avg_ft_val_features.shape)\n",
        "print(' Test features shape:', avg_ft_test_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZjbQ9bOfqm2",
        "outputId": "4685b8ea-2e3f-42ca-e5ff-6d1db50c17f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model:> Train features shape: (6642, 400)\n",
            " Test features shape: (1661, 400)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "svm = SGDClassifier(loss='log', penalty='l2', random_state=42, max_iter=1000, class_weight='balanced', alpha=0.00001)\n",
        "svm.fit(avg_ft_train_features, train_label_names)\n",
        "######### CV를 통한 평균 정확도 (너무 오래 걸려서 필요할 때만 시행)\n",
        "# svm_ft_cv_scores = cross_val_score(svm, avg_ft_train_features, train_label_names, cv=5)\n",
        "# svm_ft_cv_mean_score = np.mean(svm_ft_cv_scores)\n",
        "# print('CV Accuracy (5-fold):', svm_ft_cv_scores)\n",
        "# print('Mean CV Accuracy:', svm_ft_cv_mean_score)\n",
        "#########\n",
        "svm_ft_test_score = svm.score(avg_ft_test_features, test_label_names)\n",
        "print('Test Accuracy:', svm_ft_test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM0YRfHwjFsk",
        "outputId": "f3515d6b-8f99-4c39-a42b-74a758c8eb2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.555689343768814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastText vector_size 1000 + svm alpha default=0.0001\n",
        "\n",
        "- Test Accuracy: 0.7781215414025556\n",
        "\n",
        "fastText vector_size 1000 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7945554360744808\n",
        "\n",
        "fastText vector_size 1000 + svm alpha 0.00001, log\n",
        "\n",
        "- Test Accuracy: 0.8117607108495104\n",
        "\n",
        "fastText vector_size 640 + svm alpha default=0.0001\n",
        "\n",
        "- Test Accuracy: 0.7758409266700624\n",
        "\n",
        "fastText vector_size 640 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7922538532646631\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.01\n",
        "\n",
        "- Test Accuracy: 0.68043843\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.001\n",
        "\n",
        "- Test Accuracy: 0.7242439677778406\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.0001\n",
        "\n",
        "- Test Accuracy: 0.7700869696455185\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7906691569038051\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.000001\n",
        "\n",
        "- Test Accuracy: 0.7646348595468523\n",
        "\n",
        "fastText vector_size 40, min_count 100 + svm alpha 0.00001 , log\n",
        "\n",
        "- Test Accuracy: 0.6987379025411738"
      ],
      "metadata": {
        "id": "lSyVDN6WUDOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "parfit을 이용한 SGDClassifier 하이퍼파라미터최적화 (오류로 인해 PASS)\n",
        "\n",
        "RandomizedSearchCV을 이용한 최적화"
      ],
      "metadata": {
        "id": "ApND8_OJGPnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parfit"
      ],
      "metadata": {
        "id": "LX9kakFsGXTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge',  \n",
        "'perceptron'] \n",
        "penalty = ['l1', 'l2', 'elasticnet'] \n",
        "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
        "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
        "class_weight = ['balanced']\n",
        "eta0 = [1, 10, 100] \n",
        "param_distributions = dict(loss=loss, \n",
        "penalty=penalty, \n",
        "alpha=alpha, \n",
        "learning_rate=learning_rate, \n",
        "class_weight=class_weight, \n",
        "eta0=eta0)\n",
        "\n",
        "fit_params={\"early_stopping_rounds\":5,\n",
        "                \"eval_metric\" : \"roc_auc\", \n",
        "                \"eval_set\" : [[avg_ft_val_features, val_label_names]]\n",
        "               }\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5) \n",
        "random = RandomizedSearchCV(estimator=sgd, \n",
        "param_distributions=param_distributions, \n",
        "scoring='roc_auc', \n",
        "verbose=1, n_jobs=-1, \n",
        "n_iter=5) \n",
        "random_result = random.fit(avg_ft_train_features, train_label_names,**fit_params) \n",
        "print('Best Score: ', random_result.best_score_) \n",
        "print('Best Params: ', random_result.best_params_) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "UCZZx3WSGPHh",
        "outputId": "1cb0a710-da77-4689-c60b-7fdd8fa4ed30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-300a0f7c2437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m fit_params={\"early_stopping_rounds\":5,\n\u001b[1;32m     16\u001b[0m                 \u001b[0;34m\"eval_metric\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;34m\"eval_set\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mavg_ft_val_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                }\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg_ft_val_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_feature = document_vectorizer(corpus=tokenized([\"아메리카노\"]), model=ft_model,\n",
        "                                                     num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "sNkv-6BzkToO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75f0ed3b-0bb9-4b48-eafc-0b17b57166f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 3837.42it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 4529.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm.predict(predict_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3LFvLP5j5eg",
        "outputId": "70e1e5f6-10ce-4a94-c70d-8c9215f4183f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['라멘'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = \"/gdrive/MyDrive/2023beaver/svm_40_alpha00001_log.pickle\"\n",
        "pickle.dump(svm, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "PKZPiA7oQUWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open(filename, \"rb\"))"
      ],
      "metadata": {
        "id": "hPraFQDhREg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.predict(predict_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Fx7sm0RGnv",
        "outputId": "9924331d-ed02-4713-b042-9b3b5269f1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['튀김류', '맛살/게살'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tf-idf + sgd 분류"
      ],
      "metadata": {
        "id": "YWUdKIBZIwhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DS7ZV8NBIwds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "\n",
        "data_df = pd.read_csv(\"/content/Kor_standard_menu_clean.csv\")\n",
        "vect = TfidfVectorizer()\n",
        "X = vect.fit_transform(data_df['title'])\n",
        "y = data_df['category']\n",
        "\n",
        "model = SGDClassifier(loss='log', penalty='l2', random_state=42, max_iter=1000, class_weight='balanced', alpha=0.00001)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ySYFtNIz24",
        "outputId": "6419e4fe-979e-4edd-db04-4898cdb87e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=1e-05, class_weight='balanced', loss='log', random_state=42)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = vect.transform(['아이스 아메리카노', '돼지 국밥'])\n",
        "y_pred = model.predict(X_pred)\n",
        "\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnCwY-6PJr79",
        "outputId": "2e234731-b672-4f57-ae91-0ea8d7d743d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['커피' '국밥']\n"
          ]
        }
      ]
    }
  ]
}