{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skjaa0Gk6d_X"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dV3DzWTwjn0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqw5iRMA1XG",
        "outputId": "93d9fa6f-f559-4588-b188-7b74346bd8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=3132503 sha256=bb8c23675a51fe316579def09cdb5cbbcaad54a63acc20fd71604841f4544116\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13026041-46e5-40c8-a9ca-4451a2c8fcc7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자모 단위 FASTTEXT"
      ],
      "metadata": {
        "id": "f6F2ryDwmIcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hgtk"
      ],
      "metadata": {
        "id": "y3YLIC97EPvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f484484-9883-4608-db52-6414bb8c2ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hgtk\n",
            "  Downloading hgtk-0.1.3.tar.gz (6.2 kB)\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6688 sha256=40e5cc5178cc16b4f3d0626c5da017d81b0eaca43de14b50cff0855938797004\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/33/b8/bc2256172a415340e34f3c11ef2b0f3f391769000bb74de988\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTHzbHFvGM-8",
        "outputId": "3a40108f-b125-49c6-e2cb-571d3fba9bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 39.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 9.71 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-01 16:52:47--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22e9:9f55, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLJ477GMK&Signature=ez5T1qICTP1nBE0NDj1Khg2N69g%3D&x-amz-security-token=FwoGZXIvYXdzEHIaDIfZZYwloGwrTLTRFCK%2BAbSMLQVTbwAN9RUx%2BjlLdpSZSox0dvL77%2F7HWlKC1%2FwGnGUpDKIIESr5uB2P5TvM3XcFdE2rqjX5dcvj6ZKfzpMR39xO1T%2BsmzqS9q3pEFFhxkY0KRN%2BSPBfFafn3LPCWI7VhQf1P1wyBz8c3rUsFVzPJAmHkfjQFtoU2S%2B0d0q%2BDMxKmlAvblBbK7g9uU9ZGHvyTNRv0f9UNnrc5SnkOEdxxf4QyYnEzOvrUAOsE%2BWATx7izODIBj1E0lu4H%2B0o4PTGnQYyLQCWlklcg8zaxUoKlVLWPO0vb%2B7p511%2Ba9EdSdxFkzfxEJRIn9xO%2F0wNQ7%2F2Qw%3D%3D&Expires=1672593768 [following]\n",
            "--2023-01-01 16:52:48--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLJ477GMK&Signature=ez5T1qICTP1nBE0NDj1Khg2N69g%3D&x-amz-security-token=FwoGZXIvYXdzEHIaDIfZZYwloGwrTLTRFCK%2BAbSMLQVTbwAN9RUx%2BjlLdpSZSox0dvL77%2F7HWlKC1%2FwGnGUpDKIIESr5uB2P5TvM3XcFdE2rqjX5dcvj6ZKfzpMR39xO1T%2BsmzqS9q3pEFFhxkY0KRN%2BSPBfFafn3LPCWI7VhQf1P1wyBz8c3rUsFVzPJAmHkfjQFtoU2S%2B0d0q%2BDMxKmlAvblBbK7g9uU9ZGHvyTNRv0f9UNnrc5SnkOEdxxf4QyYnEzOvrUAOsE%2BWATx7izODIBj1E0lu4H%2B0o4PTGnQYyLQCWlklcg8zaxUoKlVLWPO0vb%2B7p511%2Ba9EdSdxFkzfxEJRIn9xO%2F0wNQ7%2F2Qw%3D%3D&Expires=1672593768\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.106.3, 52.217.226.129, 52.216.133.147, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.106.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  8.27MB/s    in 0.2s    \n",
            "\n",
            "2023-01-01 16:52:48 (8.27 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-01 16:54:15--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22c0:3470, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLZBF57GA&Signature=%2BXp4OKYkwK%2FbwHB7He5JqVMknNU%3D&x-amz-security-token=FwoGZXIvYXdzEHIaDD1Qj%2FxXHzdVKjE4hCK%2BAdU4Gv545r%2B9gksEq5n4xP3wBU23VWC0Fnw9eigPmMGIyr15Nf%2BxOiPQ1FvsPDsSrnYwm3k%2FlGYdNle950VqMEzK3LOC7mgvJAIkxofhUOLHS3WACsMylL5DurHFJQDBZV3Nx4gIXXOYsF0EJbYQ94tuUbseVTJTTX20sgVFyn8sC%2FYTb2wu82mKtHy6ziYKHuuL4G9XrMleOB0B13VoHp5DUGlPr15SxX0j7wqLrXlMLUy6WcIAQiu%2FNnxLTdkot%2FXGnQYyLSvEdXijoiOuKOTSTH5Bs9vnmKwid5EqJscHW9QIB%2BLoKw7AtRjiv3yW21q1%2Bw%3D%3D&Expires=1672593856 [following]\n",
            "--2023-01-01 16:54:16--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNLZBF57GA&Signature=%2BXp4OKYkwK%2FbwHB7He5JqVMknNU%3D&x-amz-security-token=FwoGZXIvYXdzEHIaDD1Qj%2FxXHzdVKjE4hCK%2BAdU4Gv545r%2B9gksEq5n4xP3wBU23VWC0Fnw9eigPmMGIyr15Nf%2BxOiPQ1FvsPDsSrnYwm3k%2FlGYdNle950VqMEzK3LOC7mgvJAIkxofhUOLHS3WACsMylL5DurHFJQDBZV3Nx4gIXXOYsF0EJbYQ94tuUbseVTJTTX20sgVFyn8sC%2FYTb2wu82mKtHy6ziYKHuuL4G9XrMleOB0B13VoHp5DUGlPr15SxX0j7wqLrXlMLUy6WcIAQiu%2FNnxLTdkot%2FXGnQYyLSvEdXijoiOuKOTSTH5Bs9vnmKwid5EqJscHW9QIB%2BLoKw7AtRjiv3yW21q1%2Bw%3D%3D&Expires=1672593856\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.168.251, 52.216.89.204, 3.5.11.197, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.168.251|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  63.6MB/s    in 0.7s    \n",
            "\n",
            "2023-01-01 16:54:17 (63.6 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hgtk\n",
        "from tqdm import tqdm\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "def word_to_jamo(token):\n",
        "    def to_special_token(jamo):\n",
        "      if not jamo:\n",
        "        return '-'\n",
        "      else:\n",
        "        return jamo\n",
        "    decomposed_token = ''\n",
        "\n",
        "    for char in token:\n",
        "        try:\n",
        "        # char( 음 절 ) 을 초 성 , 중 성 , 종 성 으 로 분 리\n",
        "            cho, jung, jong = hgtk.letter.decompose(char)\n",
        "\n",
        "            # 자 모 가 빈 문 자 일 경 우 특 수 문 자 - 로 대 체\n",
        "            cho = to_special_token(cho)\n",
        "            jung = to_special_token(jung)\n",
        "            jong = to_special_token(jong)\n",
        "            decomposed_token = decomposed_token + cho + jung + jong\n",
        "\n",
        "        # 만 약 char( 음 절 ) 이 한 글 이 아 닐 경 우 자 모 를 나 누 지 않 고 추 가\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                decomposed_token += char\n",
        "\n",
        "    # 단 어 토 큰 의 자 모 단 위 분 리 결 과 를 추 가\n",
        "    return decomposed_token\n",
        "\n",
        "\n",
        "mecab = Mecab()\n",
        "\n",
        "def tokenize_by_jamo(s):\n",
        "    return [word_to_jamo(token) for token in mecab.morphs(s)]"
      ],
      "metadata": {
        "id": "iTDOSr3bDjjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/final.csv\")\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.20, random_state=2)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=2)"
      ],
      "metadata": {
        "id": "pDhS9DVRpLW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4JF4av9mFXLB",
        "outputId": "2b9f75c2-8357-4314-8f0b-10c24f3c7a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 100% 전라도 배추 김치 포기 김장김치 주문'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_jamo(df['title'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Iu9VXN2MFLGu",
        "outputId": "2f10202e-9586-4d87-92f1-29da48162bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ㄱㅜㄱㄴㅐ-ㅅㅏㄴ 100% ㅈㅓㄴㄹㅏ-ㄷㅗ- ㅂㅐ-ㅊㅜ- ㄱㅣㅁㅊㅣ- ㅍㅗ-ㄱㅣ- ㄱㅣㅁㅈㅏㅇㄱㅣㅁㅊㅣ- ㅈㅜ-ㅁㅜㄴ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize_by_jamo(df['title'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0anP89z1I3JJ",
        "outputId": "145dba1f-4571-488f-e644-0a079255ca42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㄱㅜㄱㄴㅐ-ㅅㅏㄴ', '100', '%', 'ㅈㅓㄴㄹㅏ-ㄷㅗ-', 'ㅂㅐ-ㅊㅜ-', 'ㄱㅣㅁㅊㅣ-', 'ㅍㅗ-ㄱㅣ-', 'ㄱㅣㅁㅈㅏㅇ', 'ㄱㅣㅁㅊㅣ-', 'ㅈㅜ-ㅁㅜㄴ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data['title'].to_list()):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "boO9ZhMQF-3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jamo_to_word(jamo_sequence):\n",
        "    tokenized_jamo = []\n",
        "    index = 0\n",
        "\n",
        "# 1. 초 기 입 력\n",
        "# jamo_sequence = ' ﾤ ￂ ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "\n",
        "    while index < len(jamo_sequence):\n",
        "    # 문 자 가 한 글 ( 정 상 적 인 자 모 ) 이 아 닐 경 우\n",
        "        if not hgtk.checker.is_hangul(jamo_sequence[index]):\n",
        "            tokenized_jamo.append(jamo_sequence[index])\n",
        "            index = index + 1\n",
        "\n",
        "    # 문 자 가 정 상 적 인 자 모 라 면 초 성 , 중 성 , 종 성 을 하 나 의 토 큰 으 로 간 주 .\n",
        "        else:\n",
        "            tokenized_jamo.append(jamo_sequence[index:index + 3])\n",
        "            index = index + 3\n",
        "\n",
        "# 2. 자 모 단 위 토 큰 화 완 료\n",
        "# tokenized_jamo : [' ﾤ ￂ ﾱ ', ' ﾧ ￌ ﾷ ', ' ﾵ ￃ ﾷ ']\n",
        "\n",
        "        word = ''\n",
        "        try:\n",
        "            for jamo in tokenized_jamo:\n",
        "            # 초 성 , 중 성 , 종 성 의 묶 음 으 로 추 정 되 는 경 우\n",
        "                if len(jamo) == 3:\n",
        "                    if jamo[2] == \"-\":\n",
        "                    # 종 성 이 존 재 하 지 않 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1])\n",
        "                    else:\n",
        "                # 종 성 이 존 재 하 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1], jamo[2])\n",
        "                # 한 글 이 아 닌 경 우\n",
        "                else:\n",
        "                    word = word + jamo\n",
        "\n",
        "            # 복 원 중 (hgtk.letter.compose) 에 러 발 생 시 초 기 입 력 리 턴 .\n",
        "            # 복 원 이 불 가 능 한 경 우 예 시 ) ' ﾤ ! ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                return jamo_sequence\n",
        "\n",
        "        # 3. 단 어 로 복 원 완 료\n",
        "        # word : ' 남 동 생 '\n",
        "\n",
        "    return word"
      ],
      "metadata": {
        "id": "Y2lnPxhNJY4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.reset_index(inplace=True)\n",
        "val_data.reset_index(inplace=True)\n",
        "test_data.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "8pzgFzNZrc0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = tokenized(train_data)\n",
        "val_token = tokenized(val_data)\n",
        "test_token = tokenized(test_data)\n",
        "df_token = tokenized(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkQfXjWJp29y",
        "outputId": "10323d40-e913-4131-dcda-0952d5068f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159021/159021 [00:33<00:00, 4802.66it/s]\n",
            "100%|██████████| 53007/53007 [00:09<00:00, 5530.86it/s]\n",
            "100%|██████████| 53007/53007 [00:09<00:00, 5636.04it/s]\n",
            "100%|██████████| 265035/265035 [00:48<00:00, 5521.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(train_token)), unit=' line'):\n",
        "          out.write(\"__label__\" + train_data['category'][i] + \"\\t\" + ' '.join(train_token[i]) + '\\n')\n",
        "\n",
        "with open('val_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(val_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + val_data['category'][i] + \"\\t\" + ' '.join(val_token[i]) + '\\n')\n",
        "\n",
        "with open('test_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(test_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + test_data['category'][i] + \"\\t\" + ' '.join(test_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyFcLFfbLeFq",
        "outputId": "0e81fca2-07ce-4335-8714-5f7c41ff54f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159021/159021 [00:01<00:00, 124064.71 line/s]\n",
            "100%|██████████| 53007/53007 [00:00<00:00, 118129.92 line/s]\n",
            "100%|██████████| 53007/53007 [00:00<00:00, 117206.43 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('df_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(df_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + df['category'][i] + \"\\t\" + ' '.join(df_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMQvm-2RVjBA",
        "outputId": "7072281f-6490-4f3a-ae60-2c0d5f418497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 265035/265035 [00:02<00:00, 122179.43 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gensim을 통한 학습"
      ],
      "metadata": {
        "id": "v58EQIwhKa8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "0FGsnERINFyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --upgrade"
      ],
      "metadata": {
        "id": "wh95tWgWNmPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.utils import tokenize\n",
        "from gensim import utils\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "class MyIter:\n",
        "    def __iter__(self):\n",
        "        path = datapath('/content/test_data.txt')\n",
        "        with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "            for line in fin:\n",
        "                yield list(tokenize(line))\n",
        "\n",
        "model3 = FastText(vector_size=4, window=3, min_count=1)\n",
        "model3.build_vocab(corpus_iterable=MyIter())\n",
        "total_examples = model3.corpus_count\n",
        "model3.train(corpus_iterable=MyIter(), total_examples=total_examples, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uim-4v9KsfE",
        "outputId": "ee8dbd8f-5c01-4279-99e6-902e3b02e70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3276530, 4152075)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 저장"
      ],
      "metadata": {
        "id": "jf11-LHlOB57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname = 'fasttext'"
      ],
      "metadata": {
        "id": "M8O1dPKhPXgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "model3.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "LvvSg8yvOBZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = FastText.load(model_fname)"
      ],
      "metadata": {
        "id": "ssaAMu6KOKiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_gensim(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (word, similarity) in word_sequence]"
      ],
      "metadata": {
        "id": "iQvu47RyWlq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"찜닭\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nDbdO1oP1u7",
        "outputId": "c7015546-6d52-428e-9cd8-d1d2ba22a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('맛있', 0.9995765686035156),\n",
              " ('냉동', 0.9995282292366028),\n",
              " ('냉장육', 0.9994854927062988),\n",
              " ('목살', 0.9984344840049744),\n",
              " ('통살', 0.9979778528213501)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"볶음밥\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmckWbVCQXh2",
        "outputId": "57fb23da-e4e3-4cca-ce03-beeb6b59345c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('덮밥', 0.9965663552284241),\n",
              " ('즉', 0.996501088142395),\n",
              " ('닭볶음밥', 0.996482253074646),\n",
              " ('쌈밥', 0.9961134791374207),\n",
              " ('맙', 0.9931130409240723)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "업데이트"
      ],
      "metadata": {
        "id": "2E4-py6wRjLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/train_data.txt')\n",
        "old_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      old_vector.append(line)"
      ],
      "metadata": {
        "id": "_yS6qanXVGAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/val_data.txt')\n",
        "new_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      new_vector.append(line)"
      ],
      "metadata": {
        "id": "40_TR9jkSu5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.allclose(old_vector, new_vector, atol=1e-4)"
      ],
      "metadata": {
        "id": "9kvVIoqURWg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.build_vocab(new_vector, update=True)\n",
        "model3.train(new_vector, total_examples=len(new_vector), epochs=model3.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KupFKwWRkQc",
        "outputId": "273949d3-c9a7-4733-a1a6-fb2597ed5cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6759131, 21611110)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.train_supervised(input='train_data.txt', autotuneValidationFile='val_data.txt')"
      ],
      "metadata": {
        "id": "W7E-dIoPM2C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(word_to_jamo(\"강아지\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k54Mp1ZINtE3",
        "outputId": "7efc51a7-257c-450e-af00-f3646c711441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__축산물',), array([0.99634981]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "찜닭을 \"과자/떡/베이커리\" 로 구분하는 대단한 수준 "
      ],
      "metadata": {
        "id": "IzbhW-VLrbRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트\n",
        "결과는 (샘플, 정확도, 재현율)"
      ],
      "metadata": {
        "id": "HjRzmMlgrSwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.test(\"test_data.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zmCeRBugwk",
        "outputId": "5f4cb0b8-8639-44c4-a256-bb8412677d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53007, 0.8575093855528515, 0.8575093855528515)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"fasttext_supervised_basemodel.bin\") # 모 델 저 장"
      ],
      "metadata": {
        "id": "cypb4feXHBZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model2 = fasttext.train_unsupervised('df_data.txt', model='skipgram')"
      ],
      "metadata": {
        "id": "KehDpoTGH7OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.get_nearest_neighbors(word_to_jamo(\"찜닭\"), k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1R4dz_K1Wo",
        "outputId": "cb1313ed-6426-42a7-ed33-428c4e939abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8166288733482361, 'ㅊㅗㄴㄷㅏㄺ'),\n",
              " (0.791918158531189, 'ㅅㅐㅇㄷㅏㄺ'),\n",
              " (0.744603157043457, 'ㄷㅏㄺㅉㅣㅁ'),\n",
              " (0.7373501062393188, 'ㅌㅗ-ㅈㅗㅇㄷㅏㄺ'),\n",
              " (0.7371629476547241, 'ㄷㅏㄺ'),\n",
              " (0.7238197922706604, 'ㅌㅗㅇㄷㅏㄺ'),\n",
              " (0.7185007333755493, 'ㅉㅣㅁㅈㅣㄹㅂㅏㅇ'),\n",
              " (0.7107194066047668, 'ㄴㅓㄼㅈㅓㄱㄷㅏ-ㄹㅣ-'),\n",
              " (0.7090702652931213, 'ㅂㅜㄱㅊㅐ-'),\n",
              " (0.7037075161933899, 'ㅍㅏ-ㄷㅏㄺ')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (similarity, word) in word_sequence]"
      ],
      "metadata": {
        "id": "XvaOGu6_LH-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 가까운 단어(유사도 기준)"
      ],
      "metadata": {
        "id": "LqwRaWuPM0QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform(model2.get_nearest_neighbors(word_to_jamo(\"호떡\"), k=10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7wCdsuqLO1W",
        "outputId": "9ca0a7ea-0cf0-4764-c532-b29cb98c1225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('소떡', 0.7843364477157593), ('빈대떡', 0.7055262327194214), ('설기떡', 0.6995227932929993), ('부떡', 0.695621132850647), ('개떡', 0.6917065978050232), ('가래떡', 0.6824575662612915), ('떡방아', 0.6752732992172241), ('호박떡', 0.6735275983810425), ('찰떡', 0.65810227394104), ('쫀떡쫀떡', 0.654928982257843)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유추(의미 기준)"
      ],
      "metadata": {
        "id": "a7ZJ4YpeMzJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform(model2.get_analogies(word_to_jamo(\"치킨\"), word_to_jamo(\"양념\"), word_to_jamo(\"마늘\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBF5jhRgL7Kw",
        "outputId": "a7ad5b78-4837-4efe-85c7-e292672e632b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('통마늘', 0.5720704197883606),\n",
              " ('마요라', 0.5677814483642578),\n",
              " ('마노', 0.5311671495437622),\n",
              " ('마요', 0.5297998785972595),\n",
              " ('마왕', 0.5232638716697693),\n",
              " ('마니', 0.5161885619163513),\n",
              " ('마늘빵', 0.5087692141532898),\n",
              " ('마마', 0.5082238912582397),\n",
              " ('마니커', 0.5073510408401489),\n",
              " ('마', 0.5069550275802612)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 저장된 모델 DB에 삽입 과정 "
      ],
      "metadata": {
        "id": "jOL2AKFjVvz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOB 방식은 안된다. bin을 BLOB로 파싱하는데 무리가 있다"
      ],
      "metadata": {
        "id": "lNAZ3GBrZ5c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNOxkX_sV17c",
        "outputId": "161715f4-f563-463f-958a-049eff2a38dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting config\n",
            "  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import numpy\n",
        "from psycopg2.extensions import register_adapter, AsIs\n",
        "  \n",
        "def addapt_numpy_float64(numpy_float64):\n",
        "    return AsIs(numpy_float64)\n",
        "def addapt_numpy_int64(numpy_int64):\n",
        "    return AsIs(numpy_int64)\n",
        "register_adapter(numpy.float64, addapt_numpy_float64)\n",
        "register_adapter(numpy.int64, addapt_numpy_int64)\n",
        "\n",
        "conn = None\n",
        "try:\n",
        "    # connect to the PostgreSQL server\n",
        "    host = 'arjuna.db.elephantsql.com'\n",
        "    user = 'kwcuclpe'\n",
        "    password = ''\n",
        "    database = 'kwcuclpe'\n",
        "\n",
        "    conn = psycopg2.connect(\n",
        "        host=host,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "  \n",
        "    # Creating a cursor with name cur.\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"CREATE TABLE blob_datastore (s_no serial, file_name VARCHAR ( 50 ), blob_data bytea)\")\n",
        "    # SQL query to insert data into the database.\n",
        "    insert_script = '''\n",
        "        INSERT INTO blob_datastore(s_no,file_name,blob_data) VALUES (%s,%s,%s);\n",
        "    '''\n",
        "  \n",
        "    # open('File,'rb').read() is used to read the file.\n",
        "    # where open(File,'rb').read() will return the binary data of the file.\n",
        "    # psycopg2.Binary(File_in_Bytes) is used to convert the binary data to a BLOB data type.\n",
        "    BLOB_1 = psycopg2.Binary(\n",
        "        open('/content/fasttext_supervised_basemodel.bin', 'rb').read())       # Video\n",
        "    # BLOB_2 = psycopg2.Binary(\n",
        "    #     open('files\\Octa.jpg', 'rb').read())        # Image\n",
        "    # BLOB_3 = psycopg2.Binary(open('files\\Type.gif', 'rb').read())        # GIF\n",
        "    # BLOB_4 = psycopg2.Binary(open('files\\BlobNotes.pdf', 'rb').read())   # PDF\n",
        "  \n",
        "    # And Finally we pass the above mentioned values to the insert_script variable.\n",
        "    insert_values = [(1, 'fasttext_basemodel', BLOB_1)]\n",
        "  \n",
        "    # The execute() method with the insert_script & insert_value as argument.\n",
        "    for insert_value in insert_values:\n",
        "        cur.execute(insert_script, insert_value)\n",
        "        print(insert_value[0], insert_value[1],\n",
        "              \"[Binary Data]\", \"row Inserted Successfully\")\n",
        "  \n",
        "    # SQL query to fetch data from the database.\n",
        "    cur.execute('SELECT * FROM BLOB_DataStore')\n",
        "  \n",
        "    # open(file,'wb').write() is used to write the binary data to the file.\n",
        "    for row in cur.fetchall():\n",
        "        BLOB = row[2]\n",
        "        open(\"new\"+row[1], 'wb').write(BLOB)\n",
        "        print(row[0], row[1], \"BLOB Data is saved in Current Directory\")\n",
        "  \n",
        "    # Close the connection\n",
        "    cur.close()\n",
        "  \n",
        "except(Exception, psycopg2.DatabaseError) as error:\n",
        "    print(error)\n",
        "finally:\n",
        "    if conn is not None:\n",
        "        \n",
        "        # Commit the changes to the database\n",
        "        conn.commit()"
      ],
      "metadata": {
        "id": "M_ylq5qNV0HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이에 따라 워드임베딩만 fastText로 진행하고, 모델은 SVM을 사용하여 피클링을 시도해본다."
      ],
      "metadata": {
        "id": "excSxmr4d7hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "## 환경설정\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk"
      ],
      "metadata": {
        "id": "6ewbIutpebUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/final.csv\")"
      ],
      "metadata": {
        "id": "cBi0btIpedX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "wu8sxXcBetun",
        "outputId": "b47db6c7-74a7-406b-a5ca-2c0404f5aca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0                                          title category  \\\n",
              "0                0                  국내산 100% 전라도 배추 김치 포기 김장김치 주문       김치   \n",
              "1                1                              피코크 조선호텔 포기김치 8kg       김치   \n",
              "2                2                          대상 종가집 행복이온 포기김치 10kg       김치   \n",
              "3                3                      대상 종가집 전라도 행복이온 포기김치 10kg       김치   \n",
              "4                4             선화동매운실비김치 맛있게 매운 대전 선화동 실비 김치 800g       김치   \n",
              "...            ...                                            ...      ...   \n",
              "265030      266352  먹템 매콤한 낙곱새 극락 밀키트(2-3인분) 4팩 캠핑음식 용밀 간편조리식품 키트      밀키트   \n",
              "265031      266353            [연말축제 1+1] 청정원 호밍스 한우진곰탕 450g X 10개      밀키트   \n",
              "265032      266354                  프레시지 프레시지 간편한 직화용기 꼬치어묵탕 818g      밀키트   \n",
              "265033      266355                   아임셰프 마라 밀푀유나베 밀키트 쿠킹박스 (2인분)      밀키트   \n",
              "265034      266356    팟쿡 어디서든 불/렌지 없이 조리 가능한 전골 나베4종 (비화식 캠핑 백패킹)      밀키트   \n",
              "\n",
              "       sub_category  price  \n",
              "0              포기김치  15900  \n",
              "1              포기김치  51040  \n",
              "2              포기김치  34200  \n",
              "3              포기김치  46840  \n",
              "4              포기김치  11080  \n",
              "...             ...    ...  \n",
              "265030         찌개/국  63370  \n",
              "265031         찌개/국  25500  \n",
              "265032         찌개/국  11860  \n",
              "265033         찌개/국  16900  \n",
              "265034         찌개/국  18900  \n",
              "\n",
              "[265035 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-527e45a5-881d-4d03-816a-2199bd8f0ad8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "      <th>sub_category</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>국내산 100% 전라도 배추 김치 포기 김장김치 주문</td>\n",
              "      <td>김치</td>\n",
              "      <td>포기김치</td>\n",
              "      <td>15900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>피코크 조선호텔 포기김치 8kg</td>\n",
              "      <td>김치</td>\n",
              "      <td>포기김치</td>\n",
              "      <td>51040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>대상 종가집 행복이온 포기김치 10kg</td>\n",
              "      <td>김치</td>\n",
              "      <td>포기김치</td>\n",
              "      <td>34200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>대상 종가집 전라도 행복이온 포기김치 10kg</td>\n",
              "      <td>김치</td>\n",
              "      <td>포기김치</td>\n",
              "      <td>46840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>선화동매운실비김치 맛있게 매운 대전 선화동 실비 김치 800g</td>\n",
              "      <td>김치</td>\n",
              "      <td>포기김치</td>\n",
              "      <td>11080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265030</th>\n",
              "      <td>266352</td>\n",
              "      <td>먹템 매콤한 낙곱새 극락 밀키트(2-3인분) 4팩 캠핑음식 용밀 간편조리식품 키트</td>\n",
              "      <td>밀키트</td>\n",
              "      <td>찌개/국</td>\n",
              "      <td>63370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265031</th>\n",
              "      <td>266353</td>\n",
              "      <td>[연말축제 1+1] 청정원 호밍스 한우진곰탕 450g X 10개</td>\n",
              "      <td>밀키트</td>\n",
              "      <td>찌개/국</td>\n",
              "      <td>25500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265032</th>\n",
              "      <td>266354</td>\n",
              "      <td>프레시지 프레시지 간편한 직화용기 꼬치어묵탕 818g</td>\n",
              "      <td>밀키트</td>\n",
              "      <td>찌개/국</td>\n",
              "      <td>11860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265033</th>\n",
              "      <td>266355</td>\n",
              "      <td>아임셰프 마라 밀푀유나베 밀키트 쿠킹박스 (2인분)</td>\n",
              "      <td>밀키트</td>\n",
              "      <td>찌개/국</td>\n",
              "      <td>16900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265034</th>\n",
              "      <td>266356</td>\n",
              "      <td>팟쿡 어디서든 불/렌지 없이 조리 가능한 전골 나베4종 (비화식 캠핑 백패킹)</td>\n",
              "      <td>밀키트</td>\n",
              "      <td>찌개/국</td>\n",
              "      <td>18900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>265035 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-527e45a5-881d-4d03-816a-2199bd8f0ad8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-527e45a5-881d-4d03-816a-2199bd8f0ad8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-527e45a5-881d-4d03-816a-2199bd8f0ad8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_corpus, test_corpus, train_label_names, test_label_names =\\\n",
        "                                 train_test_split(np.array(data_df['title']), np.array(data_df['sub_category']),\n",
        "                                                       test_size=0.33, random_state=42)\n",
        "\n",
        "train_corpus.shape, test_corpus.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onZhWYOBesEC",
        "outputId": "23e92c2e-a500-4790-d25a-874eb70600f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((177573,), (87462,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "JEhrWhWUgzXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = tokenized(train_corpus)\n",
        "                   \n",
        "tokenized_test = tokenized(test_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRVe65age_94",
        "outputId": "cd4df378-8b59-49ad-e252-e5e58ebf2f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 177573/177573 [00:33<00:00, 5241.11it/s]\n",
            "100%|██████████| 87462/87462 [00:15<00:00, 5509.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "ft_num_features = 1000\n",
        "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
        "ft_model = FastText(tokenized_train, size=ft_num_features, window=100, \n",
        "                    min_count=2, sample=1e-3, sg=1, iter=5, workers=10)"
      ],
      "metadata": {
        "id": "sVio9k_QeDuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname=\"/gdrive/MyDrive/2023beaver/fastText_1000\"\n",
        "ft_model.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "ft_model.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "FP1OqH4tm_TK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def document_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in corpus]\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "BgnbXWVAfyPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_ft_train_features = document_vectorizer(corpus=tokenized_train, model=ft_model,\n",
        "                                                     num_features=ft_num_features)\n",
        "avg_ft_test_features = document_vectorizer(corpus=tokenized_test, model=ft_model,\n",
        "                                                    num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "uP9ueVfxfo_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('FastText model:> Train features shape:', avg_ft_train_features.shape, \n",
        "      ' Test features shape:', avg_ft_test_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZjbQ9bOfqm2",
        "outputId": "6306bebf-d531-411a-c785-2d925835ac70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model:> Train features shape: (177573, 1000)  Test features shape: (87462, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "svm = SGDClassifier(loss='hinge', penalty='l2', random_state=42, max_iter=500)\n",
        "svm.fit(avg_ft_train_features, train_label_names)\n",
        "svm_ft_cv_scores = cross_val_score(svm, avg_ft_train_features, train_label_names, cv=5)\n",
        "svm_ft_cv_mean_score = np.mean(svm_ft_cv_scores)\n",
        "print('CV Accuracy (5-fold):', svm_ft_cv_scores)\n",
        "print('Mean CV Accuracy:', svm_ft_cv_mean_score)\n",
        "svm_ft_test_score = svm.score(avg_ft_test_features, test_label_names)\n",
        "print('Test Accuracy:', svm_ft_test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM0YRfHwjFsk",
        "outputId": "f4eccd31-3320-4c72-b4a4-7a2f92056095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CV Accuracy (5-fold): [0.79904266 0.79321413 0.79709982 0.79616489 0.79855832]\n",
            "Mean CV Accuracy: 0.7968159635264409\n",
            "Test Accuracy: 0.7967917495598088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_feature = document_vectorizer(corpus=word_to_jamo(\"호떡\"), model=ft_model,\n",
        "                                                     num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "sNkv-6BzkToO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_feature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt55mKI_kgzT",
        "outputId": "757918e9-dc2b-487b-b568-5e2e94430bc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [-0.23585831, -0.09001003, -0.63167715,  0.06523085],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        ,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm.predict(predict_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3LFvLP5j5eg",
        "outputId": "3dbec0b2-277c-4bd8-ec99-035e40b31ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['차류', '차류', '차류', '차류', '차류', '차류'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}