{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skjaa0Gk6d_X"
      },
      "source": [
        "# 구글 드라이브 연동하기\n",
        "모델 체크포인트 등을 저장해 둘 구글 드라이브를 연결합니다. 자신의 구글 계정에 적용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "dV3DzWTwjn0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zqw5iRMA1XG",
        "outputId": "93d9fa6f-f559-4588-b188-7b74346bd8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.10.1-py3-none-any.whl (216 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fasttext) (1.21.6)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp38-cp38-linux_x86_64.whl size=3132503 sha256=bb8c23675a51fe316579def09cdb5cbbcaad54a63acc20fd71604841f4544116\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/61/2a/c54711a91c418ba06ba195b1d78ff24fcaad8592f2a694ac94\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQCGKzLXJuED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24fac551-3d95-4e37-f979-e78d2f3b0c98"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 자모 단위 FASTTEXT"
      ],
      "metadata": {
        "id": "f6F2ryDwmIcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hgtk"
      ],
      "metadata": {
        "id": "y3YLIC97EPvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd872209-df0a-4ed0-dce4-ea5c8dcd3d11"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hgtk\n",
            "  Downloading hgtk-0.1.3.tar.gz (6.2 kB)\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6688 sha256=6050fa49ef0c960e7f3a418183ce82aa78c83e56a68f24546aa2f32a0b97d3c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/93/33/b8/bc2256172a415340e34f3c11ef2b0f3f391769000bb74de988\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy\n",
        "\n",
        "from konlpy.tag import Mecab\n",
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab/\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTHzbHFvGM-8",
        "outputId": "7d3ce3c1-9f0c-48f2-ef7e-96d8f283f7bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
            "\u001b[K     |████████████████████████████████| 465 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n",
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 115 (delta 11), reused 10 (delta 3), pack-reused 91\u001b[K\n",
            "Receiving objects: 100% (115/115), 1.27 MiB | 15.67 MiB/s, done.\n",
            "Resolving deltas: 100% (50/50), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.8/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.4.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from konlpy) (4.9.2)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.8/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2023-01-02 12:20:54--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNGJKLYILI&Signature=jeRfzPGIhJ%2FJkHTn3Q1IiJO9Obg%3D&x-amz-security-token=FwoGZXIvYXdzEIb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDKXERDXDx8UzeM5e2CK%2BAfFceWZlsI9W1q8uGnVSQMTjoN1yGjFPm%2B06g%2BdddQ9y2WySiX5lnCflfzuQwd0GGkfpGg6i0ZEFAV66%2BKdTMxciGRkHEyDP%2Fegpm3ZC5jIxF%2BMKgGNF8sL5TVNLkm0wmOg2jCjNLz8dvGdWSxc4yB92BaRfHNW3vjxJ6ae45rWlJRUN8PvskKTr2eSH%2BG6XJ71s%2FKTM6PXl7cxl9%2B8BraRnNPMKtqHrdgJaRREesc5hrYHhDG89IDU26E%2FdEfoo3ZXLnQYyLcbQwtlcyKRISPkN2WJ8bOV5oWYUzvAr%2FFW43FvQxx6VxY7QODYLqq%2F614asbg%3D%3D&Expires=1672663525 [following]\n",
            "--2023-01-02 12:20:54--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNGJKLYILI&Signature=jeRfzPGIhJ%2FJkHTn3Q1IiJO9Obg%3D&x-amz-security-token=FwoGZXIvYXdzEIb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDKXERDXDx8UzeM5e2CK%2BAfFceWZlsI9W1q8uGnVSQMTjoN1yGjFPm%2B06g%2BdddQ9y2WySiX5lnCflfzuQwd0GGkfpGg6i0ZEFAV66%2BKdTMxciGRkHEyDP%2Fegpm3ZC5jIxF%2BMKgGNF8sL5TVNLkm0wmOg2jCjNLz8dvGdWSxc4yB92BaRfHNW3vjxJ6ae45rWlJRUN8PvskKTr2eSH%2BG6XJ71s%2FKTM6PXl7cxl9%2B8BraRnNPMKtqHrdgJaRREesc5hrYHhDG89IDU26E%2FdEfoo3ZXLnQYyLcbQwtlcyKRISPkN2WJ8bOV5oWYUzvAr%2FFW43FvQxx6VxY7QODYLqq%2F614asbg%3D%3D&Expires=1672663525\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.200.89, 3.5.11.197, 3.5.20.124, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.200.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2023-01-02 12:20:55 (21.6 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2023-01-02 12:22:00--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22e9:9f55, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMDJWJTXT&Signature=np0%2F%2FVUFEXJLvy4KNK%2FurohWM7w%3D&x-amz-security-token=FwoGZXIvYXdzEIb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDDfTYiqGcjvbZTgnGiK%2BAZ%2FX8NVxfxY5AKWBYoR8RMCJL2mMZCQrU0yAfib44cHmtq9zKCzmaLGL7Ma%2FyqE9u2TNHyPQtLMal9zABN4t0WAT9mb0nyDFn1eT1opVUJiFPa3p2rF3wriQurg3aBllkb8kGFvvBsPNzrhs3xzr5hXrBgRKlr9XmUS95Pqa5k094iR9fjV5zn7%2BCIRPtGhO78CZvP2%2FKAv3LXnKTUHmOLHWZ5TyxU08alV9qUTHdIokIt3xm%2B4AsLe9zcsvuFIoupbLnQYyLWQU50N5RD54oKOl%2FQI2ucdTP%2BkfznvWCOknUgpupnxpx%2BvI8uDyWrpv%2B9joLg%3D%3D&Expires=1672663618 [following]\n",
            "--2023-01-02 12:22:00--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNMDJWJTXT&Signature=np0%2F%2FVUFEXJLvy4KNK%2FurohWM7w%3D&x-amz-security-token=FwoGZXIvYXdzEIb%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDDfTYiqGcjvbZTgnGiK%2BAZ%2FX8NVxfxY5AKWBYoR8RMCJL2mMZCQrU0yAfib44cHmtq9zKCzmaLGL7Ma%2FyqE9u2TNHyPQtLMal9zABN4t0WAT9mb0nyDFn1eT1opVUJiFPa3p2rF3wriQurg3aBllkb8kGFvvBsPNzrhs3xzr5hXrBgRKlr9XmUS95Pqa5k094iR9fjV5zn7%2BCIRPtGhO78CZvP2%2FKAv3LXnKTUHmOLHWZ5TyxU08alV9qUTHdIokIt3xm%2B4AsLe9zcsvuFIoupbLnQYyLWQU50N5RD54oKOl%2FQI2ucdTP%2BkfznvWCOknUgpupnxpx%2BvI8uDyWrpv%2B9joLg%3D%3D&Expires=1672663618\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.219.241, 3.5.10.213, 54.231.199.217, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.219.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   114MB/s    in 0.4s    \n",
            "\n",
            "2023-01-02 12:22:00 (114 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hgtk\n",
        "from tqdm import tqdm\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "def word_to_jamo(token):\n",
        "    def to_special_token(jamo):\n",
        "      if not jamo:\n",
        "        return '-'\n",
        "      else:\n",
        "        return jamo\n",
        "    decomposed_token = ''\n",
        "\n",
        "    for char in token:\n",
        "        try:\n",
        "        # char( 음 절 ) 을 초 성 , 중 성 , 종 성 으 로 분 리\n",
        "            cho, jung, jong = hgtk.letter.decompose(char)\n",
        "\n",
        "            # 자 모 가 빈 문 자 일 경 우 특 수 문 자 - 로 대 체\n",
        "            cho = to_special_token(cho)\n",
        "            jung = to_special_token(jung)\n",
        "            jong = to_special_token(jong)\n",
        "            decomposed_token = decomposed_token + cho + jung + jong\n",
        "\n",
        "        # 만 약 char( 음 절 ) 이 한 글 이 아 닐 경 우 자 모 를 나 누 지 않 고 추 가\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                decomposed_token += char\n",
        "\n",
        "    # 단 어 토 큰 의 자 모 단 위 분 리 결 과 를 추 가\n",
        "    return decomposed_token\n",
        "\n",
        "\n",
        "mecab = Mecab()\n",
        "\n",
        "def tokenize_by_jamo(s):\n",
        "    return [word_to_jamo(token) for token in mecab.morphs(s)]"
      ],
      "metadata": {
        "id": "iTDOSr3bDjjv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/final.csv\")\n",
        "\n",
        "train_data, test_data = train_test_split(df, test_size=0.20, random_state=2)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=2)"
      ],
      "metadata": {
        "id": "pDhS9DVRpLW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4JF4av9mFXLB",
        "outputId": "2b9f75c2-8357-4314-8f0b-10c24f3c7a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'국내산 100% 전라도 배추 김치 포기 김장김치 주문'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_jamo(df['title'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Iu9VXN2MFLGu",
        "outputId": "2f10202e-9586-4d87-92f1-29da48162bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ㄱㅜㄱㄴㅐ-ㅅㅏㄴ 100% ㅈㅓㄴㄹㅏ-ㄷㅗ- ㅂㅐ-ㅊㅜ- ㄱㅣㅁㅊㅣ- ㅍㅗ-ㄱㅣ- ㄱㅣㅁㅈㅏㅇㄱㅣㅁㅊㅣ- ㅈㅜ-ㅁㅜㄴ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize_by_jamo(df['title'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0anP89z1I3JJ",
        "outputId": "145dba1f-4571-488f-e644-0a079255ca42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㄱㅜㄱㄴㅐ-ㅅㅏㄴ', '100', '%', 'ㅈㅓㄴㄹㅏ-ㄷㅗ-', 'ㅂㅐ-ㅊㅜ-', 'ㄱㅣㅁㅊㅣ-', 'ㅍㅗ-ㄱㅣ-', 'ㄱㅣㅁㅈㅏㅇ', 'ㄱㅣㅁㅊㅣ-', 'ㅈㅜ-ㅁㅜㄴ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data['title'].to_list()):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "boO9ZhMQF-3u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jamo_to_word(jamo_sequence):\n",
        "    tokenized_jamo = []\n",
        "    index = 0\n",
        "\n",
        "# 1. 초 기 입 력\n",
        "# jamo_sequence = ' ﾤ ￂ ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "\n",
        "    while index < len(jamo_sequence):\n",
        "    # 문 자 가 한 글 ( 정 상 적 인 자 모 ) 이 아 닐 경 우\n",
        "        if not hgtk.checker.is_hangul(jamo_sequence[index]):\n",
        "            tokenized_jamo.append(jamo_sequence[index])\n",
        "            index = index + 1\n",
        "\n",
        "    # 문 자 가 정 상 적 인 자 모 라 면 초 성 , 중 성 , 종 성 을 하 나 의 토 큰 으 로 간 주 .\n",
        "        else:\n",
        "            tokenized_jamo.append(jamo_sequence[index:index + 3])\n",
        "            index = index + 3\n",
        "\n",
        "# 2. 자 모 단 위 토 큰 화 완 료\n",
        "# tokenized_jamo : [' ﾤ ￂ ﾱ ', ' ﾧ ￌ ﾷ ', ' ﾵ ￃ ﾷ ']\n",
        "\n",
        "        word = ''\n",
        "        try:\n",
        "            for jamo in tokenized_jamo:\n",
        "            # 초 성 , 중 성 , 종 성 의 묶 음 으 로 추 정 되 는 경 우\n",
        "                if len(jamo) == 3:\n",
        "                    if jamo[2] == \"-\":\n",
        "                    # 종 성 이 존 재 하 지 않 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1])\n",
        "                    else:\n",
        "                # 종 성 이 존 재 하 는 경 우\n",
        "                        word = word + hgtk.letter.compose(jamo[0], jamo[1], jamo[2])\n",
        "                # 한 글 이 아 닌 경 우\n",
        "                else:\n",
        "                    word = word + jamo\n",
        "\n",
        "            # 복 원 중 (hgtk.letter.compose) 에 러 발 생 시 초 기 입 력 리 턴 .\n",
        "            # 복 원 이 불 가 능 한 경 우 예 시 ) ' ﾤ ! ﾱ ﾧ ￌ ﾷ ﾵ ￃ ﾷ '\n",
        "        except Exception as exception:\n",
        "            if type(exception).__name__ == 'NotHangulException':\n",
        "                return jamo_sequence\n",
        "\n",
        "        # 3. 단 어 로 복 원 완 료\n",
        "        # word : ' 남 동 생 '\n",
        "\n",
        "    return word"
      ],
      "metadata": {
        "id": "Y2lnPxhNJY4Y"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.reset_index(inplace=True)\n",
        "val_data.reset_index(inplace=True)\n",
        "test_data.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "8pzgFzNZrc0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = tokenized(train_data)\n",
        "val_token = tokenized(val_data)\n",
        "test_token = tokenized(test_data)\n",
        "df_token = tokenized(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkQfXjWJp29y",
        "outputId": "10323d40-e913-4131-dcda-0952d5068f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159021/159021 [00:33<00:00, 4802.66it/s]\n",
            "100%|██████████| 53007/53007 [00:09<00:00, 5530.86it/s]\n",
            "100%|██████████| 53007/53007 [00:09<00:00, 5636.04it/s]\n",
            "100%|██████████| 265035/265035 [00:48<00:00, 5521.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(train_token)), unit=' line'):\n",
        "          out.write(\"__label__\" + train_data['category'][i] + \"\\t\" + ' '.join(train_token[i]) + '\\n')\n",
        "\n",
        "with open('val_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(val_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + val_data['category'][i] + \"\\t\" + ' '.join(val_token[i]) + '\\n')\n",
        "\n",
        "with open('test_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(test_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + test_data['category'][i] + \"\\t\" + ' '.join(test_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyFcLFfbLeFq",
        "outputId": "0e81fca2-07ce-4335-8714-5f7c41ff54f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 159021/159021 [00:01<00:00, 124064.71 line/s]\n",
            "100%|██████████| 53007/53007 [00:00<00:00, 118129.92 line/s]\n",
            "100%|██████████| 53007/53007 [00:00<00:00, 117206.43 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('df_data.txt', 'w') as out:\n",
        "    for i in tqdm(range(len(df_token)), unit=' line'):\n",
        "        out.write(\"__label__\" + df['category'][i] + \"\\t\" + ' '.join(df_token[i]) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMQvm-2RVjBA",
        "outputId": "7072281f-6490-4f3a-ae60-2c0d5f418497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 265035/265035 [00:02<00:00, 122179.43 line/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gensim을 통한 학습"
      ],
      "metadata": {
        "id": "v58EQIwhKa8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "0FGsnERINFyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy --upgrade"
      ],
      "metadata": {
        "id": "wh95tWgWNmPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n",
        "from gensim.utils import tokenize\n",
        "from gensim import utils\n",
        "from gensim.test.utils import datapath\n",
        "\n",
        "class MyIter:\n",
        "    def __iter__(self):\n",
        "        path = datapath('/content/test_data.txt')\n",
        "        with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "            for line in fin:\n",
        "                yield list(tokenize(line))\n",
        "\n",
        "model3 = FastText(vector_size=4, window=3, min_count=1)\n",
        "model3.build_vocab(corpus_iterable=MyIter())\n",
        "total_examples = model3.corpus_count\n",
        "model3.train(corpus_iterable=MyIter(), total_examples=total_examples, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Uim-4v9KsfE",
        "outputId": "ee8dbd8f-5c01-4279-99e6-902e3b02e70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3276530, 4152075)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 저장"
      ],
      "metadata": {
        "id": "jf11-LHlOB57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname = 'fasttext'"
      ],
      "metadata": {
        "id": "M8O1dPKhPXgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "model3.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "LvvSg8yvOBZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = FastText.load(model_fname)"
      ],
      "metadata": {
        "id": "ssaAMu6KOKiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_gensim(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (word, similarity) in word_sequence]"
      ],
      "metadata": {
        "id": "iQvu47RyWlq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"찜닭\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nDbdO1oP1u7",
        "outputId": "c7015546-6d52-428e-9cd8-d1d2ba22a0ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('맛있', 0.9995765686035156),\n",
              " ('냉동', 0.9995282292366028),\n",
              " ('냉장육', 0.9994854927062988),\n",
              " ('목살', 0.9984344840049744),\n",
              " ('통살', 0.9979778528213501)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_gensim(model3.wv.most_similar(word_to_jamo(\"볶음밥\"), topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmckWbVCQXh2",
        "outputId": "57fb23da-e4e3-4cca-ce03-beeb6b59345c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('덮밥', 0.9965663552284241),\n",
              " ('즉', 0.996501088142395),\n",
              " ('닭볶음밥', 0.996482253074646),\n",
              " ('쌈밥', 0.9961134791374207),\n",
              " ('맙', 0.9931130409240723)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "업데이트"
      ],
      "metadata": {
        "id": "2E4-py6wRjLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/train_data.txt')\n",
        "old_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      old_vector.append(line)"
      ],
      "metadata": {
        "id": "_yS6qanXVGAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = datapath('/content/val_data.txt')\n",
        "new_vector = []\n",
        "with utils.open(path, 'r', encoding='utf-8') as fin:\n",
        "    for line in fin:\n",
        "      new_vector.append(line)"
      ],
      "metadata": {
        "id": "40_TR9jkSu5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.allclose(old_vector, new_vector, atol=1e-4)"
      ],
      "metadata": {
        "id": "9kvVIoqURWg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.build_vocab(new_vector, update=True)\n",
        "model3.train(new_vector, total_examples=len(new_vector), epochs=model3.epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KupFKwWRkQc",
        "outputId": "273949d3-c9a7-4733-a1a6-fb2597ed5cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6759131, 21611110)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "\n",
        "model = fasttext.train_supervised(input='train_data.txt', autotuneValidationFile='val_data.txt')"
      ],
      "metadata": {
        "id": "W7E-dIoPM2C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(word_to_jamo(\"강아지\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k54Mp1ZINtE3",
        "outputId": "7efc51a7-257c-450e-af00-f3646c711441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('__label__축산물',), array([0.99634981]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "찜닭을 \"과자/떡/베이커리\" 로 구분하는 대단한 수준 "
      ],
      "metadata": {
        "id": "IzbhW-VLrbRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트\n",
        "결과는 (샘플, 정확도, 재현율)"
      ],
      "metadata": {
        "id": "HjRzmMlgrSwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.test(\"test_data.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86zmCeRBugwk",
        "outputId": "5f4cb0b8-8639-44c4-a256-bb8412677d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53007, 0.8575093855528515, 0.8575093855528515)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"fasttext_supervised_basemodel.bin\") # 모 델 저 장"
      ],
      "metadata": {
        "id": "cypb4feXHBZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext\n",
        "model2 = fasttext.train_unsupervised('df_data.txt', model='skipgram')"
      ],
      "metadata": {
        "id": "KehDpoTGH7OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.get_nearest_neighbors(word_to_jamo(\"찜닭\"), k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD1R4dz_K1Wo",
        "outputId": "cb1313ed-6426-42a7-ed33-428c4e939abc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.8166288733482361, 'ㅊㅗㄴㄷㅏㄺ'),\n",
              " (0.791918158531189, 'ㅅㅐㅇㄷㅏㄺ'),\n",
              " (0.744603157043457, 'ㄷㅏㄺㅉㅣㅁ'),\n",
              " (0.7373501062393188, 'ㅌㅗ-ㅈㅗㅇㄷㅏㄺ'),\n",
              " (0.7371629476547241, 'ㄷㅏㄺ'),\n",
              " (0.7238197922706604, 'ㅌㅗㅇㄷㅏㄺ'),\n",
              " (0.7185007333755493, 'ㅉㅣㅁㅈㅣㄹㅂㅏㅇ'),\n",
              " (0.7107194066047668, 'ㄴㅓㄼㅈㅓㄱㄷㅏ-ㄹㅣ-'),\n",
              " (0.7090702652931213, 'ㅂㅜㄱㅊㅐ-'),\n",
              " (0.7037075161933899, 'ㅍㅏ-ㄷㅏㄺ')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(word_sequence):\n",
        "    return [(jamo_to_word(word), similarity) for (similarity, word) in word_sequence]"
      ],
      "metadata": {
        "id": "XvaOGu6_LH-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가장 가까운 단어(유사도 기준)"
      ],
      "metadata": {
        "id": "LqwRaWuPM0QV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(transform(model2.get_nearest_neighbors(word_to_jamo(\"호떡\"), k=10)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7wCdsuqLO1W",
        "outputId": "9ca0a7ea-0cf0-4764-c532-b29cb98c1225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('소떡', 0.7843364477157593), ('빈대떡', 0.7055262327194214), ('설기떡', 0.6995227932929993), ('부떡', 0.695621132850647), ('개떡', 0.6917065978050232), ('가래떡', 0.6824575662612915), ('떡방아', 0.6752732992172241), ('호박떡', 0.6735275983810425), ('찰떡', 0.65810227394104), ('쫀떡쫀떡', 0.654928982257843)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "유추(의미 기준)"
      ],
      "metadata": {
        "id": "a7ZJ4YpeMzJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform(model2.get_analogies(word_to_jamo(\"치킨\"), word_to_jamo(\"양념\"), word_to_jamo(\"마늘\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBF5jhRgL7Kw",
        "outputId": "a7ad5b78-4837-4efe-85c7-e292672e632b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('통마늘', 0.5720704197883606),\n",
              " ('마요라', 0.5677814483642578),\n",
              " ('마노', 0.5311671495437622),\n",
              " ('마요', 0.5297998785972595),\n",
              " ('마왕', 0.5232638716697693),\n",
              " ('마니', 0.5161885619163513),\n",
              " ('마늘빵', 0.5087692141532898),\n",
              " ('마마', 0.5082238912582397),\n",
              " ('마니커', 0.5073510408401489),\n",
              " ('마', 0.5069550275802612)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 저장된 모델 DB에 삽입 과정 "
      ],
      "metadata": {
        "id": "jOL2AKFjVvz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOB 방식은 안된다. bin을 BLOB로 파싱하는데 무리가 있다"
      ],
      "metadata": {
        "id": "lNAZ3GBrZ5c2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNOxkX_sV17c",
        "outputId": "161715f4-f563-463f-958a-049eff2a38dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting config\n",
            "  Downloading config-0.5.1-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: config\n",
            "Successfully installed config-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import numpy\n",
        "from psycopg2.extensions import register_adapter, AsIs\n",
        "  \n",
        "def addapt_numpy_float64(numpy_float64):\n",
        "    return AsIs(numpy_float64)\n",
        "def addapt_numpy_int64(numpy_int64):\n",
        "    return AsIs(numpy_int64)\n",
        "register_adapter(numpy.float64, addapt_numpy_float64)\n",
        "register_adapter(numpy.int64, addapt_numpy_int64)\n",
        "\n",
        "conn = None\n",
        "try:\n",
        "    # connect to the PostgreSQL server\n",
        "    host = 'arjuna.db.elephantsql.com'\n",
        "    user = 'kwcuclpe'\n",
        "    password = ''\n",
        "    database = 'kwcuclpe'\n",
        "\n",
        "    conn = psycopg2.connect(\n",
        "        host=host,\n",
        "        user=user,\n",
        "        password=password,\n",
        "        database=database\n",
        "    )\n",
        "  \n",
        "    # Creating a cursor with name cur.\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(\n",
        "        \"CREATE TABLE blob_datastore (s_no serial, file_name VARCHAR ( 50 ), blob_data bytea)\")\n",
        "    # SQL query to insert data into the database.\n",
        "    insert_script = '''\n",
        "        INSERT INTO blob_datastore(s_no,file_name,blob_data) VALUES (%s,%s,%s);\n",
        "    '''\n",
        "  \n",
        "    # open('File,'rb').read() is used to read the file.\n",
        "    # where open(File,'rb').read() will return the binary data of the file.\n",
        "    # psycopg2.Binary(File_in_Bytes) is used to convert the binary data to a BLOB data type.\n",
        "    BLOB_1 = psycopg2.Binary(\n",
        "        open('/content/fasttext_supervised_basemodel.bin', 'rb').read())       # Video\n",
        "    # BLOB_2 = psycopg2.Binary(\n",
        "    #     open('files\\Octa.jpg', 'rb').read())        # Image\n",
        "    # BLOB_3 = psycopg2.Binary(open('files\\Type.gif', 'rb').read())        # GIF\n",
        "    # BLOB_4 = psycopg2.Binary(open('files\\BlobNotes.pdf', 'rb').read())   # PDF\n",
        "  \n",
        "    # And Finally we pass the above mentioned values to the insert_script variable.\n",
        "    insert_values = [(1, 'fasttext_basemodel', BLOB_1)]\n",
        "  \n",
        "    # The execute() method with the insert_script & insert_value as argument.\n",
        "    for insert_value in insert_values:\n",
        "        cur.execute(insert_script, insert_value)\n",
        "        print(insert_value[0], insert_value[1],\n",
        "              \"[Binary Data]\", \"row Inserted Successfully\")\n",
        "  \n",
        "    # SQL query to fetch data from the database.\n",
        "    cur.execute('SELECT * FROM BLOB_DataStore')\n",
        "  \n",
        "    # open(file,'wb').write() is used to write the binary data to the file.\n",
        "    for row in cur.fetchall():\n",
        "        BLOB = row[2]\n",
        "        open(\"new\"+row[1], 'wb').write(BLOB)\n",
        "        print(row[0], row[1], \"BLOB Data is saved in Current Directory\")\n",
        "  \n",
        "    # Close the connection\n",
        "    cur.close()\n",
        "  \n",
        "except(Exception, psycopg2.DatabaseError) as error:\n",
        "    print(error)\n",
        "finally:\n",
        "    if conn is not None:\n",
        "        \n",
        "        # Commit the changes to the database\n",
        "        conn.commit()"
      ],
      "metadata": {
        "id": "M_ylq5qNV0HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이에 따라 워드임베딩만 fastText로 진행하고, 모델은 SVM을 사용하여 피클링을 시도해본다."
      ],
      "metadata": {
        "id": "excSxmr4d7hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 준비"
      ],
      "metadata": {
        "id": "8hTZcNw6EaYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "## 환경설정\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import nltk"
      ],
      "metadata": {
        "id": "6ewbIutpebUK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df = pd.read_csv(\"/gdrive/MyDrive/2023beaver/final_clean.csv\")"
      ],
      "metadata": {
        "id": "cBi0btIpedX_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['sub_category'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wu8sxXcBetun",
        "outputId": "6aa33e66-3f7d-4f98-ebfc-75fc9f374696"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['포기김치', '반찬세트', '장아찌', '절임류', '기타반찬류', '단무지', '조림류', '장조림', '볶음류',\n",
              "       '젓갈장류', '된장', '김해초', '과일', '견과류', '채소', '쌀', '잡곡혼합곡', '건과류', '쇠고기',\n",
              "       '닭고기', '돼지고기', '알류', '축산가공식품', '기타육류', '양고기', '오리고기', '한방재료',\n",
              "       '건강분말', '건강즙과일즙', '꿀', '인삼', '홍삼', '건강환정', '영양제', '비타민제',\n",
              "       '환자식영양보충식', '꽁치고등어', '골뱅이번데기', '햄', '참치연어', '기타통조림캔', '황도과일', '생선',\n",
              "       '해산물어패류', '피클올리브', '건어물', '차류', '주스과즙음료', '전통차음료', '건강기능성음료',\n",
              "       '우유요구르트', '커피', '청량탄산음료', '코코아', '두유', '탄산수', '어묵', '기타조미료', '고추장',\n",
              "       '별미김치', '백김치', '파김치', '갓김치', '열무김치', '깍두기', '절임배추', '액젓', '옥수수콩',\n",
              "       '면류', '총각김치', '세트', '겉절이', '물엿올리고당', '즉석국즉석탕', '기타소스드레싱',\n",
              "       '기타냉동간편조리식품', '카레짜장', '스낵', '가루분말류', '오이소박이', '튀김류', '수산가공식품',\n",
              "       '채식푸드', '양념장', '곤약', '간장', '가공안주류', '초콜릿', '떡', '한과', '쿠키',\n",
              "       '아이스크림빙수', '빵', '강정', '팝콘강냉이류', '시리얼', '젤리', '전병', '엿', '푸딩', '사탕',\n",
              "       '화과자', '껌', '만두', '기타장류', '식초', '라면', '단백질보충제', '기타다이어트식품', '굴소스',\n",
              "       '청국장', '쌈장', '메주', '누룽지', '즉석밥', '샐러드', '스프', '죽', '간식디저트', '떡볶이',\n",
              "       '피자', '핫도그', '딤섬', '도시락', '햄버거', '고춧가루', '소금', '고추냉이', '겨자', '설탕',\n",
              "       '후추', '천연감미료', '마요네즈', '오리엔탈드레싱', '스파게티파스타소스', '머스타드소스', '칠리핫소스',\n",
              "       '케첩', '돈가스소스', '스테이크바베큐소스', '발사믹드레싱', '딸기잼', '기타잼시럽', '치즈', '마가린',\n",
              "       '버터', '생크림', '휘핑크림', '연유', '콜라겐', '가르시니아', '히알루론산', '식이섬유',\n",
              "       '다이어트차', '구이', '찌개국', '맛살게살', '함박미트볼', '식용유오일', '제과제빵재료', '막걸리탁주',\n",
              "       '약주', '소주', '일반증류주', '리큐르주', '기타주류', '전통주선물세트', '과실주', '생수', '케이크',\n",
              "       '기타과자', '대상별', '기능별', '비타민', '유산균', '도시락밥류', '샐러드닭가슴살', '죽스프',\n",
              "       '만두딤섬', '떡볶이튀김어묵', '피자핫도그햄버거', '기타간편조리식품', '베이커리', '젤리캐러멜푸딩',\n",
              "       '사탕껌엿', '과자쿠키', '팝콘강냉이', '전통과자', '제로음료', '우유요거트', '파우더스무디', '면파스타',\n",
              "       '밥죽', '볶음튀김', '조림찜'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# train_corpus, test_corpus, train_label_names, test_label_names =\\\n",
        "#                                  train_test_split(np.array(data_df['title']), np.array(data_df['sub_category']),\n",
        "#                                                        test_size=0.33, random_state=42)\n",
        "train_corpus, test_corpus = train_test_split(data_df, test_size=0.2, random_state=42)\n",
        "#train_corpus, val_corpus = train_test_split(data_df, test_size=0.15, random_state=42)\n",
        "\n",
        "feature = 'title'\n",
        "target = 'sub_category'\n",
        "\n",
        "train_label_names = train_corpus[target]\n",
        "#val_label_names = val_corpus[target]\n",
        "test_label_names = test_corpus[target]\n",
        "\n",
        "train_corpus = train_corpus['title']\n",
        "#val_corpus = val_corpus['title']\n",
        "test_corpus = test_corpus['title']\n",
        "\n",
        "train_corpus.shape, test_corpus.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onZhWYOBesEC",
        "outputId": "4784b14a-d228-437f-fe69-c6a8d3e8a9c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((212028,), (53007,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenized(data):\n",
        "  tokenized_data=[]\n",
        "\n",
        "  for sample in tqdm(data):\n",
        "      tokenzied_sample = tokenize_by_jamo(sample) # 자 소 단 위 토 큰 화\n",
        "      tokenized_data.append(tokenzied_sample)\n",
        "\n",
        "  return tokenized_data"
      ],
      "metadata": {
        "id": "JEhrWhWUgzXB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = tokenized(train_corpus)\n",
        "#tokenized_val = tokenized(val_corpus)\n",
        "tokenized_test = tokenized(test_corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRVe65age_94",
        "outputId": "b880ab47-9b1a-430d-c4ee-34a6b0bc2fcc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 212028/212028 [00:41<00:00, 5104.81it/s]\n",
            "100%|██████████| 53007/53007 [00:09<00:00, 5360.18it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 준비 및 실행"
      ],
      "metadata": {
        "id": "a4MXjkxqEc0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "ft_num_features = 4 # 4의 배수에서 좋은 성능이 나온다고 함"
      ],
      "metadata": {
        "id": "nC91wbEsEVWw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
        "ft_model = FastText(tokenized_train, size=ft_num_features, window=3, \n",
        "                    min_count=-1, sample=1e-3, sg=1, iter=5, workers=10)"
      ],
      "metadata": {
        "id": "sVio9k_QeDuR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fname=f\"/gdrive/MyDrive/2023beaver/fastText_{ft_num_features}\""
      ],
      "metadata": {
        "id": "rKFmjHZkDp8r"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_model.save(model_fname)\n",
        "# https://projector.tensorflow.org/ 에서 시각화 하기 위해 모델을 따로 저장\n",
        "ft_model.wv.save_word2vec_format(model_fname + \"_vis\")"
      ],
      "metadata": {
        "id": "FP1OqH4tm_TK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미 저장된 모델 로드"
      ],
      "metadata": {
        "id": "CK-4YhbMEjL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "ft_model = FastText.load(model_fname)"
      ],
      "metadata": {
        "id": "awcnpWd3DdzE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastText 워드임베딩 pickle화 시도\n",
        "\n",
        "-> 가능은 한데, 용량이 1.3G로 상당히 크다. 문제 해결 X"
      ],
      "metadata": {
        "id": "XFW5nl54OkBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = model_fname + \".pickle\"\n",
        "pickle.dump(ft_model, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "aYKhna72OYe5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "joblib을 통한 압축 시도\n",
        "\n",
        "compress 파라미터가 압축을 의미하며, 높을수록 오래걸리지만 용량이 적어진다.(0 ~ 9까지)\n",
        "\n",
        "https://joblib.readthedocs.io/en/latest/generated/joblib.dump.html\n",
        "\n",
        "compress 9 (최대)에서 710M까지 줄여졌다.\n",
        "\n",
        "-> 여전히 문제 해결X"
      ],
      "metadata": {
        "id": "JbAz-fztQsYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "filename = model_fname + \".joblib\"\n",
        "\n",
        "# save model\n",
        "joblib.dump(ft_model, filename, compress=9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skM7lumwQwAa",
        "outputId": "d548bedf-cb2f-418c-84fd-2af026755803"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/MyDrive/2023beaver/fastText_1000.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def document_vectorizer(corpus, model, num_features):\n",
        "    vocabulary = set(model.wv.index2word)\n",
        "    \n",
        "    def average_word_vectors(words, model, vocabulary, num_features):\n",
        "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
        "        nwords = 0.\n",
        "        \n",
        "        for word in words:\n",
        "            if word in vocabulary: \n",
        "                nwords = nwords + 1.\n",
        "                feature_vector = np.add(feature_vector, model.wv[word])\n",
        "        if nwords:\n",
        "            feature_vector = np.divide(feature_vector, nwords)\n",
        "\n",
        "        return feature_vector\n",
        "\n",
        "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features)\n",
        "                    for tokenized_sentence in tqdm(corpus)]\n",
        "    return np.array(features)"
      ],
      "metadata": {
        "id": "BgnbXWVAfyPC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate averaged word vector features from word2vec model\n",
        "avg_ft_train_features = document_vectorizer(corpus=tokenized_train, model=ft_model,\n",
        "                                                     num_features=ft_num_features)\n",
        "# avg_ft_val_features = document_vectorizer(corpus=tokenized_val, model=ft_model,\n",
        "#                                                      num_features=ft_num_features)\n",
        "avg_ft_test_features = document_vectorizer(corpus=tokenized_test, model=ft_model,\n",
        "                                                    num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "uP9ueVfxfo_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c431444a-09af-43d2-fbe7-28666eb8e4d8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 212028/212028 [00:17<00:00, 12327.96it/s]\n",
            "100%|██████████| 53007/53007 [00:03<00:00, 17178.54it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('FastText model:> Train features shape:', avg_ft_train_features.shape)\n",
        "#print(' Val features shape:', avg_ft_val_features.shape)\n",
        "print(' Test features shape:', avg_ft_test_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZjbQ9bOfqm2",
        "outputId": "e1543a48-68b5-43b0-ec26-e6d657d72544"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText model:> Train features shape: (212028, 1000)\n",
            " Test features shape: (53007, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "svm = SGDClassifier(loss='log', penalty='l2', random_state=42, max_iter=1000, class_weight='balanced', alpha=0.00001)\n",
        "svm.fit(avg_ft_train_features, train_label_names)\n",
        "######### CV를 통한 평균 정확도 (너무 오래 걸려서 필요할 때만 시행)\n",
        "# svm_ft_cv_scores = cross_val_score(svm, avg_ft_train_features, train_label_names, cv=5)\n",
        "# svm_ft_cv_mean_score = np.mean(svm_ft_cv_scores)\n",
        "# print('CV Accuracy (5-fold):', svm_ft_cv_scores)\n",
        "# print('Mean CV Accuracy:', svm_ft_cv_mean_score)\n",
        "#########\n",
        "svm_ft_test_score = svm.score(avg_ft_test_features, test_label_names)\n",
        "print('Test Accuracy:', svm_ft_test_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM0YRfHwjFsk",
        "outputId": "f265c7f9-643e-4060-95c3-b5c724c69a43"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8117607108495104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "fastText vector_size 1000 + svm alpha default=0.0001\n",
        "\n",
        "- Test Accuracy: 0.7781215414025556\n",
        "\n",
        "fastText vector_size 1000 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7945554360744808\n",
        "\n",
        "fastText vector_size 1000 + svm alpha 0.00001, log\n",
        "\n",
        "- Test Accuracy: 0.8117607108495104\n",
        "\n",
        "fastText vector_size 640 + svm alpha default=0.0001\n",
        "\n",
        "- Test Accuracy: 0.7758409266700624\n",
        "\n",
        "fastText vector_size 640 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7922538532646631\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.01\n",
        "\n",
        "- Test Accuracy: 0.68043843\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.001\n",
        "\n",
        "- Test Accuracy: 0.7242439677778406\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.0001\n",
        "\n",
        "- Test Accuracy: 0.7700869696455185\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.00001\n",
        "\n",
        "- Test Accuracy: 0.7906691569038051\n",
        "\n",
        "fastText vector_size 300 + svm alpha 0.000001\n",
        "\n",
        "- Test Accuracy: 0.7646348595468523"
      ],
      "metadata": {
        "id": "lSyVDN6WUDOG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "parfit을 이용한 SGDClassifier 하이퍼파라미터최적화 (오류로 인해 PASS)\n",
        "\n",
        "RandomizedSearchCV을 이용한 최적화"
      ],
      "metadata": {
        "id": "ApND8_OJGPnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install parfit"
      ],
      "metadata": {
        "id": "LX9kakFsGXTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = ['hinge', 'log', 'modified_huber', 'squared_hinge',  \n",
        "'perceptron'] \n",
        "penalty = ['l1', 'l2', 'elasticnet'] \n",
        "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000] \n",
        "learning_rate = ['constant', 'optimal', 'invscaling', 'adaptive'] \n",
        "class_weight = ['balanced']\n",
        "eta0 = [1, 10, 100] \n",
        "param_distributions = dict(loss=loss, \n",
        "penalty=penalty, \n",
        "alpha=alpha, \n",
        "learning_rate=learning_rate, \n",
        "class_weight=class_weight, \n",
        "eta0=eta0)\n",
        "\n",
        "fit_params={\"early_stopping_rounds\":5,\n",
        "                \"eval_metric\" : \"roc_auc\", \n",
        "                \"eval_set\" : [[avg_ft_val_features, val_label_names]]\n",
        "               }\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier \n",
        "from sklearn.model_selection import RandomizedSearchCV \n",
        "sgd = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5) \n",
        "random = RandomizedSearchCV(estimator=sgd, \n",
        "param_distributions=param_distributions, \n",
        "scoring='roc_auc', \n",
        "verbose=1, n_jobs=-1, \n",
        "n_iter=5) \n",
        "random_result = random.fit(avg_ft_train_features, train_label_names,**fit_params) \n",
        "print('Best Score: ', random_result.best_score_) \n",
        "print('Best Params: ', random_result.best_params_) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "UCZZx3WSGPHh",
        "outputId": "1cb0a710-da77-4689-c60b-7fdd8fa4ed30"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-300a0f7c2437>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m fit_params={\"early_stopping_rounds\":5,\n\u001b[1;32m     16\u001b[0m                 \u001b[0;34m\"eval_metric\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 \u001b[0;34m\"eval_set\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mavg_ft_val_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_label_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                }\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'avg_ft_val_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_feature = document_vectorizer(corpus=tokenized([\"치킨\", \"김밥\"]), model=ft_model,\n",
        "                                                     num_features=ft_num_features)"
      ],
      "metadata": {
        "id": "sNkv-6BzkToO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6fae5c-aa65-4ab4-dcd4-4c08745f94bd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 7803.36it/s]\n",
            "100%|██████████| 2/2 [00:00<00:00, 8089.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_feature"
      ],
      "metadata": {
        "id": "yt55mKI_kgzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm.predict(predict_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3LFvLP5j5eg",
        "outputId": "fc4f736e-43ca-4237-ef6a-aec03df03b27"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['튀김류', '맛살게살'], dtype='<U10')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = \"/gdrive/MyDrive/2023beaver/svm_1000_alpha00001_log.pickle\"\n",
        "pickle.dump(svm, open(filename, \"wb\"))"
      ],
      "metadata": {
        "id": "PKZPiA7oQUWU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = pickle.load(open(filename, \"rb\"))"
      ],
      "metadata": {
        "id": "hPraFQDhREg4"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.predict(predict_feature)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Fx7sm0RGnv",
        "outputId": "9924331d-ed02-4713-b042-9b3b5269f1f8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['튀김류', '맛살/게살'], dtype='<U11')"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}